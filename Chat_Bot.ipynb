{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chat_Bot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPDPcDUE9xmMuskZlH8YptK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toinnn/Chat_Bot/blob/master/Chat_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QIg39CJSnDdg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa7e5cb-6d71-4c30-944d-81187f8ba640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()\n",
        "!pip install pyspark py4j\n",
        "%pip install jaro-winkler\n",
        "# !cat /proc/cpuinfo\n",
        "# !lscpu | grep 'Core(s) each processor has/per socket:'\n",
        "# !lscpu | grep 'Number of threads/core:'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwhJ0bhTGYi_",
        "outputId": "29378049-9623-4d5a-ccb6-03d936f1f95d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.7/dist-packages (0.10.9.3)\n",
            "Requirement already satisfied: jaro-winkler in /usr/local/lib/python3.7/dist-packages (2.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Git_Dir    = \"/content/drive/MyDrive/Github_Dir/Chat_Bot\"\n",
        "Neural_Dir = \"Machine-Learning__Deep-Learning\"\n",
        "with open(\"/content/drive/MyDrive/Github_Dir/acess_Token_Git.txt\",\"r\") as file:\n",
        "    acess_Token_Git = file.read()\n",
        "Git_Path   = \"https://\"+ acess_Token_Git + \"@github.com/toinnn/\" + Neural_Dir + \".git\"\n",
        "Git_CB_Path= \"https://\"+ acess_Token_Git + \"@github.com/toinnn/\" + \"Chat_Bot\" + \".git\""
      ],
      "metadata": {
        "id": "FHFrjufquZPT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"{Git_Path}\" ./temp/Machine-Learning__Deep-Learning\n",
        "!git clone \"{Git_CB_Path}\" ./temp/Chat_Bot\n",
        "\n",
        "!mv ./temp/* \"{Git_Dir}\"\n",
        "!rm -rf ./temp \n",
        "\n",
        "!rsync -aP \"{Git_Dir}\"/*  ./\n",
        "#!ln -s \"/content/drive/MyDrive/Github_Dir/Chat_Bot\" + Neural_Dir NLP"
      ],
      "metadata": {
        "id": "yxOPQqF2NNhE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13ebed54-ca57-4c21-89eb-8480855df164"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into './temp/Machine-Learning__Deep-Learning'...\n",
            "remote: Enumerating objects: 524, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 524 (delta 8), reused 10 (delta 1), pack-reused 496\u001b[K\n",
            "Receiving objects: 100% (524/524), 49.56 MiB | 19.11 MiB/s, done.\n",
            "Resolving deltas: 100% (243/243), done.\n",
            "Checking out files: 100% (162/162), done.\n",
            "Cloning into './temp/Chat_Bot'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 74 (delta 28), reused 17 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (74/74), done.\n",
            "mv: inter-device move failed: './temp/Chat_Bot' to '/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot'; unable to remove target: Directory not empty\n",
            "mv: inter-device move failed: './temp/Machine-Learning__Deep-Learning' to '/content/drive/MyDrive/Github_Dir/Chat_Bot/Machine-Learning__Deep-Learning'; unable to remove target: Directory not empty\n",
            "sending incremental file list\n",
            "Chat_Bot/\n",
            "Chat_Bot/datasetDict.pickle\n",
            "    700,156,131 100%  111.97MB/s    0:00:05 (xfr#1, to-chk=285/290)\n",
            "Chat_Bot/datasetDict_Sucinto.pickle\n",
            "    529,991,646 100%   90.74MB/s    0:00:05 (xfr#2, to-chk=284/290)\n",
            "rsync: send_files failed to open \"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/teste (1).gsheet\": Operation not supported (95)\n",
            "rsync: send_files failed to open \"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/teste.gsheet\": Operation not supported (95)\n",
            "Chat_Bot/result3.csv/\n",
            "Chat_Bot/result3.csv/._SUCCESS.crc\n",
            "              8 100%    0.01kB/s    0:00:00 (xfr#5, to-chk=222/290)\n",
            "Chat_Bot/result3.csv/.part-00000-94f3bc51-847d-44a3-a9d9-87a09b5284e8-c000.csv.crc\n",
            "      3,978,112 100%    6.13MB/s    0:00:00 (xfr#6, to-chk=221/290)\n",
            "Chat_Bot/result3.csv/_SUCCESS\n",
            "              0 100%    0.00kB/s    0:00:00 (xfr#7, to-chk=220/290)\n",
            "Chat_Bot/result3.csv/part-00000-94f3bc51-847d-44a3-a9d9-87a09b5284e8-c000.csv\n",
            "    509,196,990 100%   88.68MB/s    0:00:05 (xfr#8, to-chk=219/290)\n",
            "Machine-Learning__Deep-Learning/\n",
            "rsync error: some files/attrs were not transferred (see previous errors) (code 23) at main.c(1196) [sender=3.1.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jaro\n",
        "\n",
        "class nGram_Utils():\n",
        "    def __init__(self):\n",
        "        self.nGram = []\n",
        "        self.nGram2idx = None\n",
        "        self.n = None\n",
        "    def prepare_Text(self , text : str , n : int):\n",
        "        self.nGram = self.charNgram(text , n )\n",
        "        self.nGram = self.jaroWinkler_Sort(self.nGram , n )\n",
        "        \n",
        "        self.nGram2idx = {self.nGram[i] : i  for i in range(len(self.nGram))}\n",
        "        self.nGram2idx[\" \"] = len(self.nGram)\n",
        "\n",
        "        # return self.text2idx(text , self.nGram2idx , n )\n",
        "        \n",
        "    def charNgram(self ,text : str , n : int ) -> list:\n",
        "        text = text.split()\n",
        "        for word in text :\n",
        "            var = { word[i : i + j] : None  for i in range(0 ,len(word) -n + 1 , 1 )  for j in range(1 , n+1)    }\n",
        "            if len(word)%n != 0 :\n",
        "                falta = len(word)%n\n",
        "                var.update({ word[- falta :-i] : None for i in range(1 , falta)})\n",
        "                var.update({word[- falta :] : None})\n",
        "        \n",
        "        return list(var.keys())\n",
        "\n",
        "    def jaroWinkler_Sort(self ,nGram : list , n :int = None)-> tuple :\n",
        "        \n",
        "        if type(n) == type(1) :\n",
        "            try :\n",
        "                aux = {i :[] for i in range(1 , n + 1)}\n",
        "                for i in nGram :\n",
        "                    aux[len(i)] += [i]\n",
        "                nGram = []\n",
        "                for i in list(aux.values() )[::-1] :\n",
        "                    nGram += i\n",
        "            except :\n",
        "                print(\"Foi identificado que o n passado é menor que o usado na criação do nGram\")\n",
        "        for i in range(len(nGram) - 1 ) :\n",
        "            var = (jaro.original_metric(nGram[i] , nGram[i + 1] ) , nGram[i+1] ,i + 1 )\n",
        "            for j in range( i + 1,len(nGram)) :\n",
        "                if jaro.original_metric(nGram[i] , nGram[j] ) >  var[0] :\n",
        "                    var = (jaro.original_metric(nGram[i] , nGram[j] ) , nGram[j] , j )\n",
        "            aux = nGram[i + 1]\n",
        "            nGram[i + 1] = var[1]\n",
        "            try :\n",
        "                nGram[var[2]]= aux\n",
        "            except :\n",
        "                print(j)\n",
        "            \n",
        "        return tuple(nGram)\n",
        "    def text2idx(self , text : str , nGram2idx : dict , n )-> tuple :\n",
        "        '''Se nGram2idx não possui posição do dicionario dedicada ao espaço em \n",
        "        branco(\" \") este será representado com indíce len(nGram2idx)'''\n",
        "        text = text.split()\n",
        "        aux = []\n",
        "        for word in text :\n",
        "            begin = 0\n",
        "            size  = n\n",
        "            tkn = True\n",
        "            while tkn :\n",
        "                try :\n",
        "                    aux += [nGram2idx[word[begin:size]]]\n",
        "                    begin = size\n",
        "                    size  = n\n",
        "                    if begin == len(word):\n",
        "                        tkn   = False\n",
        "                except :\n",
        "                    size -= 1\n",
        "            try :\n",
        "              aux += [nGram2idx[\" \"]]\n",
        "            except :\n",
        "              aux += [len(nGram2idx)]\n",
        "        return tuple(aux[:-1])\n",
        "un = nGram_Utils()\n",
        "print(len({1:2,2:3}))\n",
        "print(un.charNgram(\"cincocinsa\" , 4 ))\n",
        "print(un.jaroWinkler_Sort(un.charNgram(\"cincocinsa\" , 4 ) , 4 ))\n",
        "print(jaro.jaro_metric(\"abco\",\"bc\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOLkChh_deHk",
        "outputId": "ac3ec3dc-dff9-4ad3-be85-e3ca308a621d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "['c', 'ci', 'cin', 'cinc', 'i', 'in', 'inc', 'inco', 'n', 'nc', 'nco', 'ncoc', 'co', 'coc', 'coci', 'o', 'oc', 'oci', 'ocin', 'cins', 'ins', 'insa', 's', 'sa']\n",
            "('cinc', 'cin', 'cins', 'ins', 'insa', 'in', 'inc', 'inco', 'nco', 'ncoc', 'coc', 'coci', 'co', 'c', 'ci', 'ocin', 'oci', 'oc', 'o', 'nc', 'n', 'i', 'sa', 's')\n",
            "0.8333333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib.parallel import Parallel\n",
        "%cd \"/content/{Neural_Dir}\"\n",
        "from BiLSTM import BiLSTM ,BiLSTM_Attention\n",
        "%cd /content/Chat_Bot\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col , row_number\n",
        "from pyspark.sql.window import Window\n",
        "import os\n",
        "import csv\n",
        "import pickle\n",
        "import joblib\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "df = spark.read.csv(\"/content/Chat_Bot/Kaggle_Twitter_Custumer_Support__archive/twcs/twcs.csv\" , header = True )\n",
        "# with open('/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/result3.csv/part-00000-94f3bc51-847d-44a3-a9d9-87a09b5284e8-c000.csv', 'r') as file:\n",
        "#     cs = csv.reader(file)\n",
        "#     cs = { i[0]:i for i in cs}\n",
        "\n",
        "# pickle.dump(cs , open(\"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/datasetDict.pickle\",\"wb\"))\n",
        "path = \"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/datasetDict.pickle\"\n",
        "# cs = pickle.load(open(path,\"rb\"))\n",
        "\n",
        "def loadPickle(path):\n",
        "    with open(path , \"rb\") as pt :\n",
        "        return joblib.load(pt)\n",
        "cs = loadPickle(path)\n",
        "\n",
        "\n",
        "\n",
        "print(cs[\"tweet_id\"])\n",
        "print(cs[\"1\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp7seqT8u9Ot",
        "outputId": "f223dde2-28e5-4c16-8750-9485a8828787"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Machine-Learning__Deep-Learning\n",
            "/content/Chat_Bot\n",
            "['tweet_id', 'author_id', 'inbound', 'created_at', 'text', 'response_tweet_id', 'in_response_to_tweet_id']\n",
            "['1', 'sprintcare', 'False', 'Tue Oct 31 22:10:47 +0000 2017', '@115712 I understand. I would like to assist you. We would need to get you into a private secured link to further assist.', '2', '3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cs[\"9\"])\n",
        "\n",
        "cvv = {}\n",
        "for i in list(cs.items()):\n",
        "    try :\n",
        "        cvv[i[0]] = (i[1][1] , i[1][4] , i[1][5] , i[1][6] )\n",
        "    except :\n",
        "        print(i)\n",
        "\n",
        "print(cvv[\"tweet_id\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28svrDOHy6iY",
        "outputId": "727d9335-4095-47b1-e529-5ab43919049f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['9', 'sprintcare', 'False', 'Tue Oct 31 21:46:14 +0000 2017', '@115712 I would love the chance to review the account and provide assistance.', '', '8']\n",
            "('172981', ['172981', '156475', 'True', 'Fri Nov 24 22:16:01 +0000 2017', '@AppleSupport hey! I get a message on #macOS when I connect my #iPhoneX to #MacBookPro (15\\\\\",2017) using USB-C to #Lightning cable - it says it draws too much power??!! Should I be concerned??\\\\\"\"', '172979'])\n",
            "('486515', ['486515', 'marksandspencer', 'False', 'Fri Dec 01 15:43:09 +0000 2017', '@230767 Hi Patricia, we offer 29\\\\\",31\\\\\"\\\\\" and 33\\\\\"\\\\\" lg lengths\"', 'along with 27\\\\\\\\\" in our petite range. We used to offer XL but these didn\\'t sell as well as we\\'d hoped. We\\'ll tell our buyers you\\'d like to see more longer\"'])\n",
            "('637668', ['637668', '271197', 'True', 'Wed Nov 22 20:59:28 +0000 2017', '@SpotifyCares I have a 13\\\\\",mid-2012 Macbook pro. if you need processor/RAM specs I can also provide that.\\\\\"\"', '637670'])\n",
            "('1054460', ['1054460', '369154', 'True', 'Sat Oct 14 20:51:16 +0000 2017', '@115900 Really? Why we can\\'t watch the game this afternoon? You keep having “ problems with the program \\\\\",can\\'t keep our eye on the ball that way.\\\\\"\"', '1054458'])\n",
            "('1115026', ['1115026', '383114', 'True', 'Tue Oct 24 07:02:55 +0000 2017', 'Ordino su #Amazon un Monitor 21\\\\\",una Docking Station e una tastiera. Il corriere mi porta la tastiera. Il resto lo devo ritirare alle PT 😡\\\\\"\"', '1115025'])\n",
            "('1615538', ['1615538', 'AmazonHelp', 'False', 'Sun Nov 05 14:27:01 +0000 2017', '@495480 can also call our general help number\\\\\",you can hover over the blue lettering,and our toll-free number will appear! 2/2 ^KN\\\\\"\"'])\n",
            "('1039029', ['1039029', '552875', 'True', 'Wed Oct 18 12:52:08 +0000 2017', '@365828 @GWRHelp I wonder if leg room will be improved, or will I have to endure even more discomfort for additional cost? I\\'m only 6\\' 3\\\\\",it\\'s 2017=average\\\\\"\"', '1845671'])\n",
            "('2045564', ['2045564', '604953', 'True', 'Wed Oct 18 22:22:07 +0000 2017', 'Hey @AmericanAir, if this is your idea of legroom now, I\\'m switching to @Delta or @116450 for good. I\\'m 6\\'3\\\\\",not 7\\'0\\\\\"\\\\\". https://t.co/0tuP3cbswe\\\\\"\"', '2045562'])\n",
            "('2054598', ['2054598', '593981', 'True', 'Thu Oct 05 05:33:20 +0000 2017', '@AppleSupport Can you please fix this bug? German locale, OS 10.12.6. At least there must be a warning that \\\\\",\\\\\"\\\\\" should be used. @81903 https://t.co/gHiz9Dn8e1\\\\\"\"', '2054597'])\n",
            "('2254296', ['2254296', '656662', 'True', 'Mon Nov 13 14:22:34 +0000 2017', '@AskTarget Thanks.  I\\'m 5\\'2\\\\\",and even the mid-rise short sizes are too high.  #lowrise  : )\\\\\"\"', ''])\n",
            "('2290015', ['2290015', '665254', 'True', 'Sat Nov 11 19:29:09 +0000 2017', '@MicrosoftHelps Power button 30\\\\\",Two button reboot,etc.\\\\\"\"'])\n",
            "('2449648', ['2449648', '702084', 'True', 'Sun Oct 29 15:49:32 +0000 2017', '@AzureSupport a36-f110-442b-a11e-c8111a54db07\\\\\",\\\\\"\\\\\"upn\\\\\"\\\\\":\\\\\"\\\\\"__email__\\\\\"\\\\\"\"', '\\\\\\\\\"tenantId\\\\\"\\\\\":\\\\\"\\\\\"22d63ca0-892a-4b2a-93d5-4bb0d8b4e5ad\\\\\"\\\\\"\"'])\n",
            "('2880592', ['2880592', 'UPSHelp', 'False', 'Tue Nov 28 08:39:52 +0000 2017', '@799370 Log onto https://t.co/5oMU69kAgc, click the white arrow next to your name, and scroll to preferences. On the next pg, click on Memberships in the My Choice column. Next page, click \\'Cancel My Membership\\\\\",^AD\\\\\"\"', ''])\n",
            "('author_id', 'text', 'response_tweet_id', 'in_response_to_tweet_id')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,15):\n",
        "    print(cvv[str(i)])\n",
        "# pickle.dump(cvv , open(\"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/datasetDict_Sucinto.pickle\",\"wb\"))\n"
      ],
      "metadata": {
        "id": "KquEw-Cq5XMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(df.where(df.tweet_id == 2).select(\"text\").show())\n",
        "# w2 = Window.orderBy(col(\"tweet_id\"))\n",
        "df2 = df.filter( (df.tweet_id >= 1) & (df.text != \"\") )\n",
        "\n",
        "# df2.write.format('csv').option('header',\n",
        "#                                True).mode('overwrite').option('sep',\n",
        "#                                                               ',').save(\"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/teste\")\n",
        "# os.system(\"cat /content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/teste/p* > /content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/teste.csv\")\n",
        "df2.coalesce(1).write.format('csv').option('header',True).mode(\"overwrite\").save('/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/result3.csv')\n",
        "df2.show(40)\n",
        "\n"
      ],
      "metadata": {
        "id": "N9LuFnCLVTpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path = \"/content/drive/MyDrive/Colab Notebooks/Chat_Bot.ipynb\"\n",
        "# !rsync -aP \"{path}\" /content/Chat_Bot\n",
        "\n",
        "# !git clone \"{Git_CB_Path}\" ./temp\n",
        "# !rsync -aP /content/Chat_Bot/* ./temp\n",
        "# %cd ./temp\n",
        "# !git add -u\n",
        "# !git commit -m \"update\"\n",
        "# !git config user.email \"limaalyson@hotmail.com\"\n",
        "# !git config user.name \"Alyson_Google_Colab\"\n",
        "# !git push origin master\n",
        "# %cd /content\n",
        "# !rm -rf ./temp\n"
      ],
      "metadata": {
        "id": "idUUlda31aaZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}