{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toinnn/Chat_Bot/blob/master/Chat_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtqxGolcV7iF"
      },
      "source": [
        "*Enviroment Preparation :*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIg39CJSnDdg",
        "outputId": "2288cfcd-a469-468c-d188-1e2179fd162e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwhJ0bhTGYi_",
        "outputId": "94c77142-b006-4f0c-ce77-b148f98601c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 30 kB/s \n",
            "\u001b[?25hCollecting py4j\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 44.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=0ec2b6e7cc8007d5b2d12a002f19bd1241dce3d6220b59ab0a6eb1b63e9c2f93\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n",
            "Collecting jaro-winkler\n",
            "  Downloading jaro_winkler-2.0.0-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: jaro-winkler\n",
            "Successfully installed jaro-winkler-2.0.0\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()\n",
        "!pip install pyspark py4j\n",
        "%pip install jaro-winkler\n",
        "# !cat /proc/cpuinfo\n",
        "# !lscpu | grep 'Core(s) each processor has/per socket:'\n",
        "# !lscpu | grep 'Number of threads/core:'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FHFrjufquZPT"
      },
      "outputs": [],
      "source": [
        "Git_Dir    = \"/content/drive/MyDrive/Github_Dir/Chat_Bot\"\n",
        "Neural_Dir = \"Machine-Learning__Deep-Learning\"\n",
        "with open(\"/content/drive/MyDrive/Github_Dir/acess_Token_Git.txt\",\"r\") as file:\n",
        "    acess_Token_Git = file.read()\n",
        "Git_Path   = \"https://\"+ acess_Token_Git + \"@github.com/toinnn/\" + Neural_Dir + \".git\"\n",
        "Git_CB_Path= \"https://\"+ acess_Token_Git + \"@github.com/toinnn/\" + \"Chat_Bot\" + \".git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxOPQqF2NNhE",
        "outputId": "12679c2f-08ac-436f-c6d5-f5239706d560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into './temp/Machine-Learning__Deep-Learning'...\n",
            "remote: Enumerating objects: 524, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 524 (delta 8), reused 10 (delta 1), pack-reused 496\u001b[K\n",
            "Receiving objects: 100% (524/524), 49.56 MiB | 18.48 MiB/s, done.\n",
            "Resolving deltas: 100% (243/243), done.\n",
            "Checking out files: 100% (162/162), done.\n",
            "Cloning into './temp/Chat_Bot'...\n",
            "remote: Enumerating objects: 80, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 80 (delta 32), reused 17 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (80/80), done.\n",
            "mv: inter-device move failed: './temp/Chat_Bot' to '/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot'; unable to remove target: Directory not empty\n",
            "mv: inter-device move failed: './temp/Machine-Learning__Deep-Learning' to '/content/drive/MyDrive/Github_Dir/Chat_Bot/Machine-Learning__Deep-Learning'; unable to remove target: Directory not empty\n",
            "sending incremental file list\n",
            "Chat_Bot/\n",
            "Chat_Bot/Chat_Bot.ipynb\n",
            "          3,299 100%    0.00kB/s    0:00:00 (xfr#1, to-chk=287/290)\n",
            "Chat_Bot/README.md\n",
            "             10 100%    0.03kB/s    0:00:00 (xfr#2, to-chk=286/290)\n",
            "Chat_Bot/datasetDict.pickle\n",
            "    700,156,131 100%   50.67MB/s    0:00:13 (xfr#3, to-chk=285/290)\n",
            "Chat_Bot/datasetDict_Sucinto.pickle\n",
            "    529,991,646 100%   49.56MB/s    0:00:10 (xfr#4, to-chk=284/290)\n",
            "rsync: send_files failed to open \"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/teste (1).gsheet\": Operation not supported (95)\n",
            "Chat_Bot/teste.csv\n",
            "         11,663 100%   25.54kB/s    0:00:00 (xfr#6, to-chk=282/290)\n",
            "rsync: send_files failed to open \"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/teste.gsheet\": Operation not supported (95)\n",
            "Chat_Bot/.git/\n",
            "Chat_Bot/.git/HEAD\n",
            "             23 100%    0.03kB/s    0:00:00 (xfr#8, to-chk=276/290)\n",
            "Chat_Bot/.git/config\n",
            "            304 100%    0.26kB/s    0:00:01 (xfr#9, to-chk=275/290)\n",
            "Chat_Bot/.git/description\n",
            "             73 100%    0.00kB/s    0:00:00 (xfr#10, to-chk=274/290)\n",
            "Chat_Bot/.git/index\n",
            "            217 100%    0.59kB/s    0:00:00 (xfr#11, to-chk=273/290)\n",
            "Chat_Bot/.git/packed-refs\n",
            "            114 100%    0.16kB/s    0:00:00 (xfr#12, to-chk=272/290)\n",
            "Chat_Bot/.git/branches/\n",
            "Chat_Bot/.git/hooks/\n",
            "Chat_Bot/.git/hooks/applypatch-msg.sample\n",
            "            478 100%    0.45kB/s    0:00:01 (xfr#13, to-chk=265/290)\n",
            "Chat_Bot/.git/hooks/commit-msg.sample\n",
            "            896 100%    0.59kB/s    0:00:01 (xfr#14, to-chk=264/290)\n",
            "Chat_Bot/.git/hooks/fsmonitor-watchman.sample\n",
            "          3,327 100%    0.00kB/s    0:00:00 (xfr#15, to-chk=263/290)\n",
            "Chat_Bot/.git/hooks/post-update.sample\n",
            "            189 100%    0.57kB/s    0:00:00 (xfr#16, to-chk=262/290)\n",
            "Chat_Bot/.git/hooks/pre-applypatch.sample\n",
            "            424 100%    0.63kB/s    0:00:00 (xfr#17, to-chk=261/290)\n",
            "Chat_Bot/.git/hooks/pre-commit.sample\n",
            "          1,642 100%    1.49kB/s    0:00:01 (xfr#18, to-chk=260/290)\n",
            "Chat_Bot/.git/hooks/pre-push.sample\n",
            "          1,348 100%    0.91kB/s    0:00:01 (xfr#19, to-chk=259/290)\n",
            "Chat_Bot/.git/hooks/pre-rebase.sample\n",
            "          4,898 100%    0.00kB/s    0:00:00 (xfr#20, to-chk=258/290)\n",
            "Chat_Bot/.git/hooks/pre-receive.sample\n",
            "            544 100%    1.33kB/s    0:00:00 (xfr#21, to-chk=257/290)\n",
            "Chat_Bot/.git/hooks/prepare-commit-msg.sample\n",
            "          1,492 100%    1.66kB/s    0:00:00 (xfr#22, to-chk=256/290)\n",
            "Chat_Bot/.git/hooks/update.sample\n",
            "          3,610 100%    2.80kB/s    0:00:01 (xfr#23, to-chk=255/290)\n",
            "Chat_Bot/.git/info/\n",
            "Chat_Bot/.git/info/exclude\n",
            "            240 100%    0.00kB/s    0:00:00 (xfr#24, to-chk=254/290)\n",
            "Chat_Bot/.git/logs/\n",
            "Chat_Bot/.git/logs/HEAD\n",
            "            223 100%    0.67kB/s    0:00:00 (xfr#25, to-chk=253/290)\n",
            "Chat_Bot/.git/logs/refs/\n",
            "Chat_Bot/.git/logs/refs/heads/\n",
            "Chat_Bot/.git/logs/refs/heads/master\n",
            "            223 100%    0.28kB/s    0:00:00 (xfr#26, to-chk=249/290)\n",
            "Chat_Bot/.git/logs/refs/remotes/\n",
            "Chat_Bot/.git/logs/refs/remotes/origin/\n",
            "Chat_Bot/.git/logs/refs/remotes/origin/HEAD\n",
            "            223 100%    0.20kB/s    0:00:01 (xfr#27, to-chk=247/290)\n",
            "Chat_Bot/.git/objects/\n",
            "Chat_Bot/.git/objects/25/\n",
            "Chat_Bot/.git/objects/25/a921de47c254abfbfa2d7e64f488f5c5ca542f\n",
            "            184 100%    0.13kB/s    0:00:01 (xfr#28, to-chk=238/290)\n",
            "Chat_Bot/.git/objects/26/\n",
            "Chat_Bot/.git/objects/26/a35f7e049556b046d99a890d80b6441250f3f6\n",
            "          1,159 100%    0.00kB/s    0:00:00 (xfr#29, to-chk=237/290)\n",
            "Chat_Bot/.git/objects/52/\n",
            "Chat_Bot/.git/objects/52/0c30119bd35c98cb124c7be47d1489d7f44b63\n",
            "            519 100%    1.45kB/s    0:00:00 (xfr#30, to-chk=236/290)\n",
            "Chat_Bot/.git/objects/7a/\n",
            "Chat_Bot/.git/objects/7a/0cdddda78e49f26c5ad3399ed2bb33c46872ef\n",
            "             92 100%    0.14kB/s    0:00:00 (xfr#31, to-chk=235/290)\n",
            "Chat_Bot/.git/objects/ac/\n",
            "Chat_Bot/.git/objects/ac/b198f99a209cabc91d5fe67d8f70c72f7617ae\n",
            "             26 100%    0.03kB/s    0:00:01 (xfr#32, to-chk=234/290)\n",
            "Chat_Bot/.git/objects/b9/\n",
            "Chat_Bot/.git/objects/b9/9e3a8eb6481ee059fa4d1638dbcebd672d9101\n",
            "             54 100%    0.04kB/s    0:00:01 (xfr#33, to-chk=233/290)\n",
            "Chat_Bot/.git/objects/info/\n",
            "Chat_Bot/.git/objects/pack/\n",
            "Chat_Bot/.git/refs/\n",
            "Chat_Bot/.git/refs/heads/\n",
            "Chat_Bot/.git/refs/heads/master\n",
            "             41 100%    0.00kB/s    0:00:00 (xfr#34, to-chk=229/290)\n",
            "Chat_Bot/.git/refs/remotes/\n",
            "Chat_Bot/.git/refs/remotes/origin/\n",
            "Chat_Bot/.git/refs/remotes/origin/HEAD\n",
            "             32 100%    0.09kB/s    0:00:00 (xfr#35, to-chk=227/290)\n",
            "Chat_Bot/.git/refs/tags/\n",
            "Chat_Bot/Kaggle_Twitter_Custumer_Support__archive/\n",
            "Chat_Bot/Kaggle_Twitter_Custumer_Support__archive/sample.csv\n",
            "         17,357 100%   27.52kB/s    0:00:00 (xfr#36, to-chk=226/290)\n",
            "Chat_Bot/Kaggle_Twitter_Custumer_Support__archive/twcs/\n",
            "Chat_Bot/Kaggle_Twitter_Custumer_Support__archive/twcs/.~lock.twcs.csv#\n",
            "             94 100%    0.11kB/s    0:00:00 (xfr#37, to-chk=224/290)\n",
            "Chat_Bot/Kaggle_Twitter_Custumer_Support__archive/twcs/twcs.csv\n",
            "    516,508,641 100%   33.06MB/s    0:00:14 (xfr#38, to-chk=223/290)\n",
            "Chat_Bot/result3.csv/\n",
            "Chat_Bot/result3.csv/._SUCCESS.crc\n",
            "              8 100%    0.01kB/s    0:00:01 (xfr#39, to-chk=222/290)\n",
            "Chat_Bot/result3.csv/.part-00000-692d37e8-d394-44fa-a930-3e9dc3ce4df5-c000.csv.crc\n",
            "      3,978,112 100%   42.28MB/s    0:00:00 (xfr#40, to-chk=221/290)\n",
            "Chat_Bot/result3.csv/_SUCCESS\n",
            "              0 100%    0.00kB/s    0:00:00 (xfr#41, to-chk=220/290)\n",
            "Chat_Bot/result3.csv/part-00000-692d37e8-d394-44fa-a930-3e9dc3ce4df5-c000.csv\n",
            "    509,196,990 100%   39.07MB/s    0:00:12 (xfr#42, to-chk=219/290)\n",
            "Chat_Bot/teste/\n",
            "Chat_Bot/teste/._SUCCESS.crc\n",
            "              8 100%    0.02kB/s    0:00:00 (xfr#43, to-chk=218/290)\n",
            "Chat_Bot/teste/.part-00000-112eaf24-cef8-423b-8389-7edc8a1b9ab9-c000.csv.crc\n",
            "             40 100%    0.06kB/s    0:00:00 (xfr#44, to-chk=217/290)\n",
            "Chat_Bot/teste/.part-00001-112eaf24-cef8-423b-8389-7edc8a1b9ab9-c000.csv.crc\n",
            "             20 100%    0.02kB/s    0:00:01 (xfr#45, to-chk=216/290)\n",
            "Chat_Bot/teste/.part-00002-112eaf24-cef8-423b-8389-7edc8a1b9ab9-c000.csv.crc\n",
            "             48 100%    0.03kB/s    0:00:01 (xfr#46, to-chk=215/290)\n",
            "Chat_Bot/teste/.part-00003-112eaf24-cef8-423b-8389-7edc8a1b9ab9-c000.csv.crc\n",
            "             24 100%    0.00kB/s    0:00:00 (xfr#47, to-chk=214/290)\n",
            "Chat_Bot/teste/_SUCCESS\n",
            "              0 100%    0.00kB/s    0:00:00 (xfr#48, to-chk=213/290)\n",
            "Chat_Bot/teste/part-00000-112eaf24-cef8-423b-8389-7edc8a1b9ab9-c000.csv\n",
            "          3,621 100%   10.88kB/s    0:00:00 (xfr#49, to-chk=212/290)\n",
            "Chat_Bot/teste/part-00001-112eaf24-cef8-423b-8389-7edc8a1b9ab9-c000.csv\n",
            "          1,253 100%    1.85kB/s    0:00:00 (xfr#50, to-chk=211/290)\n",
            "Chat_Bot/teste/part-00002-112eaf24-cef8-423b-8389-7edc8a1b9ab9-c000.csv\n",
            "          4,759 100%    4.97kB/s    0:00:00 (xfr#51, to-chk=210/290)\n",
            "Chat_Bot/teste/part-00003-112eaf24-cef8-423b-8389-7edc8a1b9ab9-c000.csv\n",
            "          2,030 100%    1.65kB/s    0:00:01 (xfr#52, to-chk=209/290)\n",
            "Machine-Learning__Deep-Learning/\n",
            "Machine-Learning__Deep-Learning/.gitattributes\n",
            "             66 100%    0.00kB/s    0:00:00 (xfr#53, to-chk=208/290)\n",
            "Machine-Learning__Deep-Learning/.gitignore\n",
            "            205 100%    0.51kB/s    0:00:00 (xfr#54, to-chk=207/290)\n",
            "Machine-Learning__Deep-Learning/BiGRU.py\n",
            "         12,920 100%   17.40kB/s    0:00:00 (xfr#55, to-chk=206/290)\n",
            "Machine-Learning__Deep-Learning/BiLSTM.py\n",
            "         30,417 100%   27.45kB/s    0:00:01 (xfr#56, to-chk=205/290)\n",
            "Machine-Learning__Deep-Learning/README.md\n",
            "          1,028 100%    0.71kB/s    0:00:01 (xfr#57, to-chk=204/290)\n",
            "Machine-Learning__Deep-Learning/Tener.py\n",
            "         14,346 100%    0.00kB/s    0:00:00 (xfr#58, to-chk=203/290)\n",
            "Machine-Learning__Deep-Learning/workspace.code-workspace\n",
            "            165 100%    0.50kB/s    0:00:00 (xfr#59, to-chk=202/290)\n",
            "Machine-Learning__Deep-Learning/.git/\n",
            "Machine-Learning__Deep-Learning/.git/HEAD\n",
            "             23 100%    0.03kB/s    0:00:00 (xfr#60, to-chk=199/290)\n",
            "Machine-Learning__Deep-Learning/.git/config\n",
            "            327 100%    0.28kB/s    0:00:01 (xfr#61, to-chk=198/290)\n",
            "Machine-Learning__Deep-Learning/.git/description\n",
            "             73 100%    0.05kB/s    0:00:01 (xfr#62, to-chk=197/290)\n",
            "Machine-Learning__Deep-Learning/.git/index\n",
            "         22,160 100%    0.00kB/s    0:00:00 (xfr#63, to-chk=196/290)\n",
            "Machine-Learning__Deep-Learning/.git/packed-refs\n",
            "            114 100%    0.34kB/s    0:00:00 (xfr#64, to-chk=195/290)\n",
            "Machine-Learning__Deep-Learning/.git/branches/\n",
            "Machine-Learning__Deep-Learning/.git/hooks/\n",
            "Machine-Learning__Deep-Learning/.git/hooks/applypatch-msg.sample\n",
            "            478 100%    0.80kB/s    0:00:00 (xfr#65, to-chk=188/290)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/commit-msg.sample\n",
            "            896 100%    0.88kB/s    0:00:00 (xfr#66, to-chk=187/290)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/fsmonitor-watchman.sample\n",
            "          3,327 100%    2.44kB/s    0:00:01 (xfr#67, to-chk=186/290)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/post-update.sample\n",
            "            189 100%    0.00kB/s    0:00:00 (xfr#68, to-chk=185/290)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/pre-applypatch.sample\n",
            "            424 100%    1.34kB/s    0:00:00 (xfr#69, to-chk=184/290)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/pre-commit.sample\n",
            "          1,642 100%    2.71kB/s    0:00:00 (xfr#70, to-chk=183/290)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/pre-push.sample\n",
            "          1,348 100%    1.30kB/s    0:00:01 (xfr#71, to-chk=182/290)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/pre-rebase.sample\n",
            "          4,898 100%    3.57kB/s    0:00:01 (xfr#72, to-chk=181/290)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/pre-receive.sample\n",
            "            544 100%    0.00kB/s    0:00:00 (xfr#73, to-chk=180/290)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/prepare-commit-msg.sample\n",
            "          1,492 100%    3.62kB/s    0:00:00 (xfr#74, to-chk=179/290)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/update.sample\n",
            "          3,610 100%    4.55kB/s    0:00:00 (xfr#75, to-chk=178/290)\n",
            "Machine-Learning__Deep-Learning/.git/info/\n",
            "Machine-Learning__Deep-Learning/.git/info/exclude\n",
            "            240 100%    0.20kB/s    0:00:01 (xfr#76, to-chk=177/290)\n",
            "Machine-Learning__Deep-Learning/.git/logs/\n",
            "Machine-Learning__Deep-Learning/.git/logs/HEAD\n",
            "            246 100%    0.00kB/s    0:00:00 (xfr#77, to-chk=176/290)\n",
            "Machine-Learning__Deep-Learning/.git/logs/refs/\n",
            "Machine-Learning__Deep-Learning/.git/logs/refs/heads/\n",
            "Machine-Learning__Deep-Learning/.git/logs/refs/heads/master\n",
            "            246 100%    1.01kB/s    0:00:00 (xfr#78, to-chk=172/290)\n",
            "Machine-Learning__Deep-Learning/.git/logs/refs/remotes/\n",
            "Machine-Learning__Deep-Learning/.git/logs/refs/remotes/origin/\n",
            "Machine-Learning__Deep-Learning/.git/logs/refs/remotes/origin/HEAD\n",
            "            246 100%    0.50kB/s    0:00:00 (xfr#79, to-chk=170/290)\n",
            "Machine-Learning__Deep-Learning/.git/objects/\n",
            "Machine-Learning__Deep-Learning/.git/objects/info/\n",
            "Machine-Learning__Deep-Learning/.git/objects/pack/\n",
            "Machine-Learning__Deep-Learning/.git/objects/pack/pack-f79357c92226a6acdbf8ce1883b4f8afe6463e73.idx\n",
            "         15,744 100%   18.00kB/s    0:00:00 (xfr#80, to-chk=167/290)\n",
            "Machine-Learning__Deep-Learning/.git/objects/pack/pack-f79357c92226a6acdbf8ce1883b4f8afe6463e73.pack\n",
            "     51,965,768 100%   15.05MB/s    0:00:03 (xfr#81, to-chk=166/290)\n",
            "Machine-Learning__Deep-Learning/.git/refs/\n",
            "Machine-Learning__Deep-Learning/.git/refs/heads/\n",
            "Machine-Learning__Deep-Learning/.git/refs/heads/master\n",
            "             41 100%    0.00kB/s    0:00:00 (xfr#82, to-chk=162/290)\n",
            "Machine-Learning__Deep-Learning/.git/refs/remotes/\n",
            "Machine-Learning__Deep-Learning/.git/refs/remotes/origin/\n",
            "Machine-Learning__Deep-Learning/.git/refs/remotes/origin/HEAD\n",
            "             32 100%    0.04kB/s    0:00:00 (xfr#83, to-chk=160/290)\n",
            "Machine-Learning__Deep-Learning/.git/refs/tags/\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/1-n=0.005_dim=30_maxAge=1_momentum=0.01_maxErro=0.005.savedSkipGram\n",
            "     23,456,083 100%   13.52MB/s    0:00:01 (xfr#84, to-chk=159/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/1-n=0.005_dim=30_maxAge=2_momentum=0.01_maxErro=0.005.savedSkipGram\n",
            "     23,456,083 100%   18.55MB/s    0:00:01 (xfr#85, to-chk=158/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/Ner_Test.py\n",
            "         10,061 100%   18.64kB/s    0:00:00 (xfr#86, to-chk=157/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/ark_Target_Test_W2Vec.pickle\n",
            "          6,167 100%    7.09kB/s    0:00:00 (xfr#87, to-chk=156/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/ark_Target_W2Vec.pickle\n",
            "         15,185 100%   12.30kB/s    0:00:01 (xfr#88, to-chk=155/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/ark_Test_W2Vec.pickle\n",
            "     23,254,529 100%   44.03MB/s    0:00:00 (xfr#89, to-chk=154/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/ark_W2Vec.pickle\n",
            "     67,820,763 100%   24.27MB/s    0:00:02 (xfr#90, to-chk=153/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/classesTarget_Entity_materias_W2Vec.pickle\n",
            "            341 100%    0.38kB/s    0:00:00 (xfr#91, to-chk=152/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/skip_Gram.py\n",
            "         11,402 100%    9.23kB/s    0:00:01 (xfr#92, to-chk=151/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/.vscode/\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/.vscode/settings.json\n",
            "             70 100%    0.00kB/s    0:00:00 (xfr#93, to-chk=147/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/__pycache__/\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/__pycache__/BiLSTM.cpython-38.pyc\n",
            "         15,961 100%   40.59kB/s    0:00:00 (xfr#94, to-chk=146/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/__pycache__/Tener.cpython-38.pyc\n",
            "         12,266 100%   16.78kB/s    0:00:00 (xfr#95, to-chk=145/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/__pycache__/skip_Gram.cpython-38.pyc\n",
            "          8,643 100%    7.58kB/s    0:00:01 (xfr#96, to-chk=144/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/airr8014220212_meta.json\n",
            "          2,270 100%    1.53kB/s    0:00:01 (xfr#97, to-chk=143/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/desktop.ini\n",
            "             74 100%    0.00kB/s    0:00:00 (xfr#98, to-chk=142/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/20150110436469APC_meta.json\n",
            "          1,396 100%    4.21kB/s    0:00:00 (xfr#99, to-chk=139/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AC10024133855890001_meta.json\n",
            "          3,330 100%    4.43kB/s    0:00:00 (xfr#100, to-chk=138/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AC1TCU_meta.json\n",
            "          5,027 100%    4.66kB/s    0:00:01 (xfr#101, to-chk=137/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AC1TJAC_meta.json\n",
            "          2,970 100%    2.23kB/s    0:00:01 (xfr#102, to-chk=136/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AC1TJMG_meta.json\n",
            "          3,153 100%    0.00kB/s    0:00:00 (xfr#103, to-chk=135/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AC20150110436469APC_meta.json\n",
            "          1,201 100%    3.64kB/s    0:00:00 (xfr#104, to-chk=134/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/ACO2821STF_meta.json\n",
            "          1,281 100%    1.72kB/s    0:00:00 (xfr#105, to-chk=133/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/ACORDAOTCU11602016_meta.json\n",
            "          1,883 100%    1.77kB/s    0:00:01 (xfr#106, to-chk=132/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/ACORDAOTCU25052016_meta.json\n",
            "          1,635 100%    1.12kB/s    0:00:01 (xfr#107, to-chk=131/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/ADI1TJDFT_meta.json\n",
            "          2,141 100%    0.00kB/s    0:00:00 (xfr#108, to-chk=130/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/ADI2TJDFT_meta.json\n",
            "          1,122 100%    3.65kB/s    0:00:00 (xfr#109, to-chk=129/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AIAgRAgI6193ARAGUARIMG_meta.json\n",
            "          2,458 100%    3.77kB/s    0:00:00 (xfr#110, to-chk=128/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AIRR10006691020135020322_meta.json\n",
            "          3,473 100%    3.27kB/s    0:00:01 (xfr#111, to-chk=127/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AIRR15708820115050222_meta.json\n",
            "          1,987 100%    1.45kB/s    0:00:01 (xfr#112, to-chk=126/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AIRR285001420095060020_meta.json\n",
            "            888 100%    0.00kB/s    0:00:00 (xfr#113, to-chk=125/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AIRR3731820145060141_meta.json\n",
            "          3,895 100%   10.17kB/s    0:00:00 (xfr#114, to-chk=124/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AIRR3999520145020086_meta.json\n",
            "            820 100%    1.04kB/s    0:00:00 (xfr#115, to-chk=123/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AIRR581406820065030079_meta.json\n",
            "            947 100%    0.82kB/s    0:00:01 (xfr#116, to-chk=122/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AP00000794920137060006_meta.json\n",
            "          2,252 100%    0.00kB/s    0:00:00 (xfr#117, to-chk=121/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AP00001415620157010201_meta.json\n",
            "          2,343 100%    7.36kB/s    0:00:00 (xfr#118, to-chk=120/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AP00001441420167030203_meta.json\n",
            "          2,521 100%    3.81kB/s    0:00:00 (xfr#119, to-chk=119/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AP771420167080008PA_meta.json\n",
            "          1,733 100%    1.75kB/s    0:00:00 (xfr#120, to-chk=118/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/APO1TJDFT_meta.json\n",
            "          2,485 100%    1.87kB/s    0:00:01 (xfr#121, to-chk=117/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/Ag10000170733596001_meta.json\n",
            "          1,550 100%    0.00kB/s    0:00:00 (xfr#122, to-chk=116/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/Ag10105170208398001_meta.json\n",
            "            700 100%    2.18kB/s    0:00:00 (xfr#123, to-chk=115/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AgAIRR11889820145030011_meta.json\n",
            "          1,540 100%    2.36kB/s    0:00:00 (xfr#124, to-chk=114/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AgAIRR617420125150072_meta.json\n",
            "          1,299 100%    1.27kB/s    0:00:01 (xfr#125, to-chk=113/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AgCr10582160008758001_meta.json\n",
            "          1,033 100%    0.77kB/s    0:00:01 (xfr#126, to-chk=112/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AgRg1STM_meta.json\n",
            "          1,772 100%    0.00kB/s    0:00:00 (xfr#127, to-chk=111/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AgRgSTJ1_meta.json\n",
            "          1,506 100%    4.44kB/s    0:00:00 (xfr#128, to-chk=110/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AgRgSTJ2_meta.json\n",
            "          4,414 100%    6.45kB/s    0:00:00 (xfr#129, to-chk=109/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AgRgTSE1_meta.json\n",
            "            976 100%    0.96kB/s    0:00:00 (xfr#130, to-chk=108/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AgRgTSE3_meta.json\n",
            "          1,606 100%    1.16kB/s    0:00:01 (xfr#131, to-chk=107/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/Agr10540170008341001_meta.json\n",
            "          1,384 100%    0.00kB/s    0:00:00 (xfr#132, to-chk=106/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/CP32320177080008PA_meta.json\n",
            "          2,393 100%    8.11kB/s    0:00:00 (xfr#133, to-chk=105/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/DespSEPLAGDF_meta.json\n",
            "            285 100%    0.48kB/s    0:00:00 (xfr#134, to-chk=104/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/ED1STM_meta.json\n",
            "          1,710 100%    1.82kB/s    0:00:00 (xfr#135, to-chk=103/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/ED1TJAC_meta.json\n",
            "          2,088 100%    1.65kB/s    0:00:01 (xfr#136, to-chk=102/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/EDAgRgTSE2_meta.json\n",
            "          2,241 100%    0.00kB/s    0:00:00 (xfr#137, to-chk=101/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/EDEDARR208420135040232_meta.json\n",
            "          1,866 100%    4.95kB/s    0:00:00 (xfr#138, to-chk=100/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/EDRR1TST_meta.json\n",
            "            840 100%    1.08kB/s    0:00:00 (xfr#139, to-chk=99/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/EEDRR9715120105020002_meta.json\n",
            "          2,849 100%    2.61kB/s    0:00:01 (xfr#140, to-chk=98/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/ERR731004520105130003_meta.json\n",
            "          9,321 100%    6.42kB/s    0:00:01 (xfr#141, to-chk=97/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/HC04798525420128130000_meta.json\n",
            "          4,928 100%    0.00kB/s    0:00:00 (xfr#142, to-chk=96/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/HC10000150589281000_meta.json\n",
            "          3,360 100%   10.90kB/s    0:00:00 (xfr#143, to-chk=95/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/HC10000170833503000_meta.json\n",
            "          1,742 100%    2.71kB/s    0:00:00 (xfr#144, to-chk=94/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/HC110260SP_meta.json\n",
            "          4,221 100%    4.11kB/s    0:00:01 (xfr#145, to-chk=93/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/HC151914AgRES_meta.json\n",
            "          1,296 100%    0.94kB/s    0:00:01 (xfr#146, to-chk=92/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/HC340624SP_meta.json\n",
            "          2,552 100%    0.00kB/s    0:00:00 (xfr#147, to-chk=91/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/HC418951PR_meta.json\n",
            "            467 100%    1.42kB/s    0:00:00 (xfr#148, to-chk=90/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/HC70000692720177000000_meta.json\n",
            "          2,001 100%    3.46kB/s    0:00:00 (xfr#149, to-chk=89/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/HC70000845920187000000_meta.json\n",
            "          1,219 100%    1.30kB/s    0:00:00 (xfr#150, to-chk=88/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/INSTRUCAOON06043378120186000000_meta.json\n",
            "            659 100%    0.53kB/s    0:00:01 (xfr#151, to-chk=87/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/Lei11788_meta.json\n",
            "            694 100%    0.45kB/s    0:00:01 (xfr#152, to-chk=86/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/LoaDF2018_meta.json\n",
            "            257 100%    0.00kB/s    0:00:00 (xfr#153, to-chk=85/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/Pet128TSE5_meta.json\n",
            "          1,350 100%    3.73kB/s    0:00:00 (xfr#154, to-chk=84/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/Port77DF_meta.json\n",
            "            499 100%    0.75kB/s    0:00:00 (xfr#155, to-chk=83/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/REE5908TSE4_meta.json\n",
            "          4,897 100%    4.91kB/s    0:00:00 (xfr#156, to-chk=82/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/REsp1583083RS_meta.json\n",
            "          4,740 100%    3.31kB/s    0:00:01 (xfr#157, to-chk=81/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/RR-578030-46.1999.5.04.0018_meta.json\n",
            "          3,504 100%    0.00kB/s    0:00:00 (xfr#158, to-chk=80/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/RR14976020105020085_meta.json\n",
            "          3,156 100%    9.40kB/s    0:00:00 (xfr#159, to-chk=79/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/RR2574407120025020372_meta.json\n",
            "          8,649 100%   12.15kB/s    0:00:00 (xfr#160, to-chk=78/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/RR474820145230056_meta.json\n",
            "            880 100%    0.78kB/s    0:00:01 (xfr#161, to-chk=77/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/RR942006420095040028_meta.json\n",
            "          3,232 100%    2.11kB/s    0:00:01 (xfr#162, to-chk=76/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/Rcl3495STJ_meta.json\n",
            "          1,721 100%    0.00kB/s    0:00:00 (xfr#163, to-chk=75/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/TCU4687_meta.json\n",
            "          4,583 100%   13.94kB/s    0:00:00 (xfr#164, to-chk=74/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/TSTRR16037920105200001_meta.json\n",
            "          2,712 100%    4.22kB/s    0:00:00 (xfr#165, to-chk=73/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/adi3767_meta.json\n",
            "          1,030 100%    1.08kB/s    0:00:00 (xfr#166, to-chk=72/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/airr801422012_meta.json\n",
            "          1,883 100%    1.47kB/s    0:00:01 (xfr#167, to-chk=71/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/lei11340_meta.json\n",
            "            733 100%    0.00kB/s    0:00:00 (xfr#168, to-chk=70/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/20150110436469APC.txt\n",
            "         10,793 100%   34.22kB/s    0:00:00 (xfr#169, to-chk=69/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AC10024133855890001.txt\n",
            "         18,477 100%   25.93kB/s    0:00:00 (xfr#170, to-chk=68/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AC1TCU.txt\n",
            "         36,860 100%   35.85kB/s    0:00:01 (xfr#171, to-chk=67/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AC1TJAC.txt\n",
            "         40,518 100%   99.17kB/s    0:00:00 (xfr#172, to-chk=66/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AC1TJMG.txt\n",
            "         19,952 100%   24.76kB/s    0:00:00 (xfr#173, to-chk=65/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AC20150110436469APC.txt\n",
            "          9,580 100%    8.17kB/s    0:00:01 (xfr#174, to-chk=64/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/ACO2821STF.txt\n",
            "         64,656 100%   30.41MB/s    0:00:00 (xfr#175, to-chk=63/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/ACORDAOTCU11602016.txt\n",
            "        135,006 100%  311.68kB/s    0:00:00 (xfr#176, to-chk=62/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/ACORDAOTCU25052016.txt\n",
            "         45,125 100%   55.78kB/s    0:00:00 (xfr#177, to-chk=61/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/ADI1TJDFT.txt\n",
            "         92,043 100%   81.86kB/s    0:00:01 (xfr#178, to-chk=60/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/ADI2TJDFT.txt\n",
            "         59,003 100%  146.24kB/s    0:00:00 (xfr#179, to-chk=59/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AIAgRAgI6193ARAGUARIMG.txt\n",
            "         17,078 100%   21.77kB/s    0:00:00 (xfr#180, to-chk=58/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AIRR10006691020135020322.txt\n",
            "         16,091 100%   13.06kB/s    0:00:01 (xfr#181, to-chk=57/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AIRR15708820115050222.txt\n",
            "         34,952 100%    2.08MB/s    0:00:00 (xfr#182, to-chk=56/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AIRR285001420095060020.txt\n",
            "          7,927 100%   26.69kB/s    0:00:00 (xfr#183, to-chk=55/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AIRR3731820145060141.txt\n",
            "         21,951 100%   37.74kB/s    0:00:00 (xfr#184, to-chk=54/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AIRR3999520145020086.txt\n",
            "          5,664 100%    5.88kB/s    0:00:00 (xfr#185, to-chk=53/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AIRR581406820065030079.txt\n",
            "          8,343 100%    6.65kB/s    0:00:01 (xfr#186, to-chk=52/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AP00000794920137060006.txt\n",
            "         44,306 100%   11.00MB/s    0:00:00 (xfr#187, to-chk=51/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AP00001415620157010201.txt\n",
            "         25,977 100%   83.45kB/s    0:00:00 (xfr#188, to-chk=50/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AP00001441420167030203.txt\n",
            "        135,590 100%  142.84kB/s    0:00:00 (xfr#189, to-chk=49/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AP771420167080008PA.txt\n",
            "         13,983 100%   11.07kB/s    0:00:01 (xfr#190, to-chk=48/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/APO1TJDFT.txt\n",
            "         22,924 100%    0.00kB/s    0:00:00 (xfr#191, to-chk=47/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/Ag10000170733596001.txt\n",
            "          8,281 100%   27.60kB/s    0:00:00 (xfr#192, to-chk=46/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/Ag10105170208398001.txt\n",
            "          6,774 100%    9.95kB/s    0:00:00 (xfr#193, to-chk=45/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AgAIRR11889820145030011.txt\n",
            "         10,794 100%   10.92kB/s    0:00:00 (xfr#194, to-chk=44/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AgAIRR617420125150072.txt\n",
            "          8,723 100%    6.73kB/s    0:00:01 (xfr#195, to-chk=43/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AgCr10582160008758001.txt\n",
            "         16,878 100%    0.00kB/s    0:00:00 (xfr#196, to-chk=42/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AgRg1STM.txt\n",
            "         15,001 100%   49.32kB/s    0:00:00 (xfr#197, to-chk=41/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AgRgSTJ1.txt\n",
            "         13,675 100%   21.89kB/s    0:00:00 (xfr#198, to-chk=40/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AgRgSTJ2.txt\n",
            "         29,636 100%   31.12kB/s    0:00:00 (xfr#199, to-chk=39/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AgRgTSE1.txt\n",
            "         18,913 100%   13.84kB/s    0:00:01 (xfr#200, to-chk=38/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AgRgTSE3.txt\n",
            "         34,422 100%    1.58MB/s    0:00:00 (xfr#201, to-chk=37/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/Agr10540170008341001.txt\n",
            "          8,199 100%   21.76kB/s    0:00:00 (xfr#202, to-chk=36/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/CP32320177080008PA.txt\n",
            "         16,135 100%   22.19kB/s    0:00:00 (xfr#203, to-chk=35/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/DespSEPLAGDF.txt\n",
            "         13,017 100%   12.00kB/s    0:00:01 (xfr#204, to-chk=34/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/ED1STM.txt\n",
            "         19,102 100%   12.93kB/s    0:00:01 (xfr#205, to-chk=33/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/ED1TJAC.txt\n",
            "         27,151 100%    0.00kB/s    0:00:00 (xfr#206, to-chk=32/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/EDAgRgTSE2.txt\n",
            "         11,025 100%   36.01kB/s    0:00:00 (xfr#207, to-chk=31/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/EDEDARR208420135040232.txt\n",
            "          8,468 100%   12.32kB/s    0:00:00 (xfr#208, to-chk=30/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/EDRR1TST.txt\n",
            "         10,686 100%   10.96kB/s    0:00:00 (xfr#209, to-chk=29/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/EEDRR9715120105020002.txt\n",
            "         31,100 100%   24.39kB/s    0:00:01 (xfr#210, to-chk=28/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/ERR731004520105130003.txt\n",
            "         55,918 100%   22.08MB/s    0:00:00 (xfr#211, to-chk=27/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/HC04798525420128130000.txt\n",
            "         22,249 100%   59.20kB/s    0:00:00 (xfr#212, to-chk=26/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/HC10000150589281000.txt\n",
            "         14,893 100%   21.68kB/s    0:00:00 (xfr#213, to-chk=25/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/HC10000170833503000.txt\n",
            "         13,011 100%   12.49kB/s    0:00:01 (xfr#214, to-chk=24/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/HC110260SP.txt\n",
            "         83,130 100%   60.99kB/s    0:00:01 (xfr#215, to-chk=23/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/HC151914AgRES.txt\n",
            "         21,614 100%   74.32kB/s    0:00:00 (xfr#216, to-chk=22/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/HC340624SP.txt\n",
            "         23,529 100%   39.28kB/s    0:00:00 (xfr#217, to-chk=21/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/HC418951PR.txt\n",
            "          7,990 100%    9.07kB/s    0:00:00 (xfr#218, to-chk=20/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/HC70000692720177000000.txt\n",
            "         21,415 100%   16.95kB/s    0:00:01 (xfr#219, to-chk=19/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/HC70000845920187000000.txt\n",
            "         16,059 100%    0.00kB/s    0:00:00 (xfr#220, to-chk=18/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/INSTRUCAOON06043378120186000000.txt\n",
            "          2,213 100%    7.43kB/s    0:00:00 (xfr#221, to-chk=17/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/Lei11788.txt\n",
            "         17,658 100%   27.63kB/s    0:00:00 (xfr#222, to-chk=16/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/LoaDF2018.txt\n",
            "          6,201 100%    6.39kB/s    0:00:00 (xfr#223, to-chk=15/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/Pet128TSE5.txt\n",
            "         16,322 100%   12.20kB/s    0:00:01 (xfr#224, to-chk=14/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/Port77DF.txt\n",
            "          3,859 100%    0.00kB/s    0:00:00 (xfr#225, to-chk=13/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/REE5908TSE4.txt\n",
            "         40,098 100%  118.30kB/s    0:00:00 (xfr#226, to-chk=12/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/REsp1583083RS.txt\n",
            "         34,833 100%   52.41kB/s    0:00:00 (xfr#227, to-chk=11/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/RR-578030-46.1999.5.04.0018.txt\n",
            "         23,391 100%   22.53kB/s    0:00:01 (xfr#228, to-chk=10/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/RR14976020105020085.txt\n",
            "         35,635 100%   26.54kB/s    0:00:01 (xfr#229, to-chk=9/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/RR2574407120025020372.txt\n",
            "         47,510 100%  113.44kB/s    0:00:00 (xfr#230, to-chk=8/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/RR474820145230056.txt\n",
            "          2,686 100%    3.70kB/s    0:00:00 (xfr#231, to-chk=7/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/RR942006420095040028.txt\n",
            "         35,498 100%   30.60kB/s    0:00:01 (xfr#232, to-chk=6/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/Rcl3495STJ.txt\n",
            "         13,408 100%   35.01kB/s    0:00:00 (xfr#233, to-chk=5/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/TCU4687.txt\n",
            "         27,620 100%   41.56kB/s    0:00:00 (xfr#234, to-chk=4/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/TSTRR16037920105200001.txt\n",
            "         89,515 100%   84.71kB/s    0:00:01 (xfr#235, to-chk=3/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/adi3767.txt\n",
            "         30,898 100%   96.71kB/s    0:00:00 (xfr#236, to-chk=2/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/airr801422012.txt\n",
            "         20,016 100%   32.10kB/s    0:00:00 (xfr#237, to-chk=1/290)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/lei11340.txt\n",
            "         34,566 100%   34.73kB/s    0:00:00 (xfr#238, to-chk=0/290)\n",
            "rsync error: some files/attrs were not transferred (see previous errors) (code 23) at main.c(1196) [sender=3.1.2]\n"
          ]
        }
      ],
      "source": [
        "!git clone \"{Git_Path}\" ./temp/Machine-Learning__Deep-Learning\n",
        "!git clone \"{Git_CB_Path}\" ./temp/Chat_Bot\n",
        "\n",
        "!mv ./temp/* \"{Git_Dir}\"\n",
        "!rm -rf ./temp \n",
        "\n",
        "!rsync -aP \"{Git_Dir}\"/*  ./\n",
        "#!ln -s \"/content/drive/MyDrive/Github_Dir/Chat_Bot\" + Neural_Dir NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOLkChh_deHk",
        "outputId": "dd753d91-8ff4-4a68-eb39-9ae1fdae00bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "['c', 'ci', 'cin', 'cinc', 'i', 'in', 'inc', 'inco', 'n', 'nc', 'nco', 'ncoc', 'co', 'coc', 'coci', 'o', 'oc', 'oci', 'ocin', 'cins', 'ins', 'insa', 's', 'sa']\n",
            "('cinc', 'cin', 'cins', 'ins', 'insa', 'in', 'inc', 'inco', 'nco', 'ncoc', 'coc', 'coci', 'co', 'c', 'ci', 'ocin', 'oci', 'oc', 'o', 'nc', 'n', 'i', 'sa', 's')\n",
            "0.8333333333333334\n"
          ]
        }
      ],
      "source": [
        "import jaro\n",
        "\n",
        "class nGram_Utils():\n",
        "    def __init__(self):\n",
        "        self.nGram = []\n",
        "        self.nGram2idx = None\n",
        "        self.n = None\n",
        "    def prepare_Text(self , text : str , n : int):\n",
        "        self.nGram = self.charNgram(text , n )\n",
        "        self.nGram = self.jaroWinkler_Sort(self.nGram , n )\n",
        "        \n",
        "        self.nGram2idx = {self.nGram[i] : i  for i in range(len(self.nGram))}\n",
        "        self.nGram2idx[\" \"] = len(self.nGram)\n",
        "\n",
        "        # return self.text2idx(text , self.nGram2idx , n )\n",
        "        \n",
        "    def charNgram(self ,text : str , n : int ) -> list:\n",
        "        text = text.split()\n",
        "        for word in text :\n",
        "            var = { word[i : i + j] : None  for i in range(0 ,len(word) -n + 1 , 1 )  for j in range(1 , n+1)    }\n",
        "            if len(word)%n != 0 :\n",
        "                falta = len(word)%n\n",
        "                var.update({ word[- falta :-i] : None for i in range(1 , falta)})\n",
        "                var.update({word[- falta :] : None})\n",
        "        \n",
        "        return list(var.keys())\n",
        "\n",
        "    def jaroWinkler_Sort(self ,nGram : list , n :int = None)-> tuple :\n",
        "        \n",
        "        if type(n) == type(1) :\n",
        "            try :\n",
        "                aux = {i :[] for i in range(1 , n + 1)}\n",
        "                for i in nGram :\n",
        "                    aux[len(i)] += [i]\n",
        "                nGram = []\n",
        "                for i in list(aux.values() )[::-1] :\n",
        "                    nGram += i\n",
        "            except :\n",
        "                print(\"Foi identificado que o n passado é menor que o usado na criação do nGram\")\n",
        "        for i in range(len(nGram) - 1 ) :\n",
        "            var = (jaro.original_metric(nGram[i] , nGram[i + 1] ) , nGram[i+1] ,i + 1 )\n",
        "            for j in range( i + 1,len(nGram)) :\n",
        "                if jaro.original_metric(nGram[i] , nGram[j] ) >  var[0] :\n",
        "                    var = (jaro.original_metric(nGram[i] , nGram[j] ) , nGram[j] , j )\n",
        "            aux = nGram[i + 1]\n",
        "            nGram[i + 1] = var[1]\n",
        "            try :\n",
        "                nGram[var[2]]= aux\n",
        "            except :\n",
        "                print(j)\n",
        "            \n",
        "        return tuple(nGram)\n",
        "    def text2idx(self , text : str , nGram2idx : dict , n )-> tuple :\n",
        "        '''Se nGram2idx não possui posição do dicionario dedicada ao espaço em \n",
        "        branco(\" \") este será representado com indíce len(nGram2idx)'''\n",
        "        text = text.split()\n",
        "        aux = []\n",
        "        for word in text :\n",
        "            begin = 0\n",
        "            size  = n\n",
        "            tkn = True\n",
        "            while tkn :\n",
        "                try :\n",
        "                    aux += [nGram2idx[word[begin:size]]]\n",
        "                    begin = size\n",
        "                    size  = n\n",
        "                    if begin == len(word):\n",
        "                        tkn   = False\n",
        "                except :\n",
        "                    size -= 1\n",
        "            try :\n",
        "              aux += [nGram2idx[\" \"]]\n",
        "            except :\n",
        "              aux += [len(nGram2idx)]\n",
        "        return tuple(aux[:-1])\n",
        "un = nGram_Utils()\n",
        "print(len({1:2,2:3}))\n",
        "print(un.charNgram(\"cincocinsa\" , 4 ))\n",
        "print(un.jaroWinkler_Sort(un.charNgram(\"cincocinsa\" , 4 ) , 4 ))\n",
        "print(jaro.jaro_metric(\"abco\",\"bc\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qAuxLKLTcUO"
      },
      "source": [
        "### \\> *Data* *Preparation :*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sTHoamoAqR4",
        "outputId": "ed050575-836a-4c25-84c4-75f5d941611b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Machine-Learning__Deep-Learning\n",
            "teste\n",
            "/content/Chat_Bot\n"
          ]
        }
      ],
      "source": [
        "from joblib.parallel import Parallel\n",
        "%cd \"/content/{Neural_Dir}\"\n",
        "from BiLSTM import BiLSTM ,BiLSTM_Attention\n",
        "%cd /content/Chat_Bot\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col , row_number\n",
        "from pyspark.sql.window import Window\n",
        "import os\n",
        "import csv\n",
        "import pickle\n",
        "import joblib\n",
        "from joblib import Parallel, delayed\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FvV3MMUiap_"
      },
      "source": [
        "* *Load & Clean Dataset :*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mp7seqT8u9Ot"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# spark = SparkSession.builder.getOrCreate()\n",
        "# df = spark.read.csv(\"/content/Chat_Bot/Kaggle_Twitter_Custumer_Support__archive/twcs/twcs.csv\" , header = True )\n",
        "\n",
        "# df = df.filter( (df.tweet_id >= 1) & (df.text != \"\") )\n",
        "\n",
        "# df.write.format('csv').option('header',\n",
        "#                                True).mode('overwrite').option('sep',\n",
        "#                                                               ',').save(\"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/teste\")\n",
        "# os.system(\"cat /content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/teste/p* > /content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/teste.csv\")\n",
        "# df.coalesce(1).write.format('csv').option('header',True).mode(\"overwrite\").save('/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/result3.csv')\n",
        "# df.show(40)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9LuFnCLVTpq",
        "outputId": "df0887a2-89d6-43d8-e678-c702fef44a1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tweet_id', 'author_id', 'inbound', 'created_at', 'text', 'response_tweet_id', 'in_response_to_tweet_id']\n",
            "['1', 'sprintcare', 'False', 'Tue Oct 31 22:10:47 +0000 2017', '@115712 I understand. I would like to assist you. We would need to get you into a private secured link to further assist.', '2', '3']\n"
          ]
        }
      ],
      "source": [
        "# with open('/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/result3.csv/part-00000-94f3bc51-847d-44a3-a9d9-87a09b5284e8-c000.csv', 'r') as file:\n",
        "#     cs = csv.reader(file)\n",
        "#     cs = { i[0]:i for i in cs}\n",
        "\n",
        "# pickle.dump(cs , open(\"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/datasetDict.pickle\",\"wb\"))\n",
        "path = \"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/datasetDict.pickle\"\n",
        "# cs = pickle.load(open(path,\"rb\"))\n",
        "\n",
        "def loadPickle(path):\n",
        "    with open(path , \"rb\") as pt :\n",
        "        return joblib.load(pt)\n",
        "data_dict = loadPickle(path)\n",
        "# cs = loadPickle(path)\n",
        "\n",
        "\n",
        "print(data_dict[\"tweet_id\"])\n",
        "print(data_dict[\"1\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28svrDOHy6iY",
        "outputId": "345458c2-8c7a-49ff-fc1a-cf7826c23a93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('172981', ['172981', '156475', 'True', 'Fri Nov 24 22:16:01 +0000 2017', '@AppleSupport hey! I get a message on #macOS when I connect my #iPhoneX to #MacBookPro (15\\\\\",2017) using USB-C to #Lightning cable - it says it draws too much power??!! Should I be concerned??\\\\\"\"', '172979'])\n",
            "('486515', ['486515', 'marksandspencer', 'False', 'Fri Dec 01 15:43:09 +0000 2017', '@230767 Hi Patricia, we offer 29\\\\\",31\\\\\"\\\\\" and 33\\\\\"\\\\\" lg lengths\"', 'along with 27\\\\\\\\\" in our petite range. We used to offer XL but these didn\\'t sell as well as we\\'d hoped. We\\'ll tell our buyers you\\'d like to see more longer\"'])\n",
            "('637668', ['637668', '271197', 'True', 'Wed Nov 22 20:59:28 +0000 2017', '@SpotifyCares I have a 13\\\\\",mid-2012 Macbook pro. if you need processor/RAM specs I can also provide that.\\\\\"\"', '637670'])\n",
            "('1054460', ['1054460', '369154', 'True', 'Sat Oct 14 20:51:16 +0000 2017', '@115900 Really? Why we can\\'t watch the game this afternoon? You keep having “ problems with the program \\\\\",can\\'t keep our eye on the ball that way.\\\\\"\"', '1054458'])\n",
            "('1115026', ['1115026', '383114', 'True', 'Tue Oct 24 07:02:55 +0000 2017', 'Ordino su #Amazon un Monitor 21\\\\\",una Docking Station e una tastiera. Il corriere mi porta la tastiera. Il resto lo devo ritirare alle PT 😡\\\\\"\"', '1115025'])\n",
            "('1615538', ['1615538', 'AmazonHelp', 'False', 'Sun Nov 05 14:27:01 +0000 2017', '@495480 can also call our general help number\\\\\",you can hover over the blue lettering,and our toll-free number will appear! 2/2 ^KN\\\\\"\"'])\n",
            "('1039029', ['1039029', '552875', 'True', 'Wed Oct 18 12:52:08 +0000 2017', '@365828 @GWRHelp I wonder if leg room will be improved, or will I have to endure even more discomfort for additional cost? I\\'m only 6\\' 3\\\\\",it\\'s 2017=average\\\\\"\"', '1845671'])\n",
            "('2045564', ['2045564', '604953', 'True', 'Wed Oct 18 22:22:07 +0000 2017', 'Hey @AmericanAir, if this is your idea of legroom now, I\\'m switching to @Delta or @116450 for good. I\\'m 6\\'3\\\\\",not 7\\'0\\\\\"\\\\\". https://t.co/0tuP3cbswe\\\\\"\"', '2045562'])\n",
            "('2054598', ['2054598', '593981', 'True', 'Thu Oct 05 05:33:20 +0000 2017', '@AppleSupport Can you please fix this bug? German locale, OS 10.12.6. At least there must be a warning that \\\\\",\\\\\"\\\\\" should be used. @81903 https://t.co/gHiz9Dn8e1\\\\\"\"', '2054597'])\n",
            "('2254296', ['2254296', '656662', 'True', 'Mon Nov 13 14:22:34 +0000 2017', '@AskTarget Thanks.  I\\'m 5\\'2\\\\\",and even the mid-rise short sizes are too high.  #lowrise  : )\\\\\"\"', ''])\n",
            "('2290015', ['2290015', '665254', 'True', 'Sat Nov 11 19:29:09 +0000 2017', '@MicrosoftHelps Power button 30\\\\\",Two button reboot,etc.\\\\\"\"'])\n",
            "('2449648', ['2449648', '702084', 'True', 'Sun Oct 29 15:49:32 +0000 2017', '@AzureSupport a36-f110-442b-a11e-c8111a54db07\\\\\",\\\\\"\\\\\"upn\\\\\"\\\\\":\\\\\"\\\\\"__email__\\\\\"\\\\\"\"', '\\\\\\\\\"tenantId\\\\\"\\\\\":\\\\\"\\\\\"22d63ca0-892a-4b2a-93d5-4bb0d8b4e5ad\\\\\"\\\\\"\"'])\n",
            "('2880592', ['2880592', 'UPSHelp', 'False', 'Tue Nov 28 08:39:52 +0000 2017', '@799370 Log onto https://t.co/5oMU69kAgc, click the white arrow next to your name, and scroll to preferences. On the next pg, click on Memberships in the My Choice column. Next page, click \\'Cancel My Membership\\\\\",^AD\\\\\"\"', ''])\n",
            "('author_id', 'text', 'response_tweet_id', 'in_response_to_tweet_id')\n"
          ]
        }
      ],
      "source": [
        "cvv = {}\n",
        "for i in list(data_dict.items()):\n",
        "    try :\n",
        "        cvv[i[0]] = (i[1][1] , i[1][4] , i[1][5] , i[1][6] )\n",
        "    except :\n",
        "        print(i)\n",
        "\n",
        "print(cvv[\"tweet_id\"])\n",
        "cs = None\n",
        "data_dict = None\n",
        "# pickle.dump(cvv , open(\"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/datasetDict_Sucinto.pickle\",\"wb\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7GZGyDmCCWC",
        "outputId": "9748d0e9-ee0d-4c37-ca81-dc5a47db1956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', '25', '12', '40']\n"
          ]
        }
      ],
      "source": [
        "cvv = pickle.load(open(\"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/datasetDict_Sucinto.pickle\",\"rb\"))\n",
        "#Regex : /^\\d+(,\\d+)*$/\n",
        "def str2list(input : str )-> list :\n",
        "    return re.findall( r'\\d+' , input )\n",
        "def up_catch_talk(data : dict , id : int , output:dict = {} , down : bool = True) -> dict :\n",
        "    try :\n",
        "        var = data[str(id)]        \n",
        "        try :\n",
        "            var = output[id]\n",
        "            return\n",
        "        except :\n",
        "            try:\n",
        "                for i in str2list(data[str(id)][2]) :\n",
        "                    up_catch_talk(data , int(i) , output , up = False )\n",
        "                    output.update({id : (data[str(id)][1] , [output[int(i)][0]] + output[int(i)][1]  ) })\n",
        "            except:\n",
        "                output.update({id : ( data[str(id)][1] , [] ) })\n",
        "        if down == True :\n",
        "            for i in str2list(data[str(id)][3]) :\n",
        "                up_catch_talk(data , int(i) , output , down = False )\n",
        "    except :\n",
        "        return\n",
        "def down_catch_talk(data : dict , id : int , output:dict = {} , up : bool = True) -> dict :\n",
        "    try :\n",
        "        var = data[str(id)]\n",
        "        try :\n",
        "            var = output[id]\n",
        "            return\n",
        "        except :\n",
        "            try:\n",
        "                for i in str2list(data[str(id)][3]) :\n",
        "                    down_catch_talk(data , int(i) , output , up = False )\n",
        "                    # print(f\"data[str(id)][1]{data[str(id)][1]}\")\n",
        "                    # print(f\"output[i][0] == {output[int(i)]}\")\n",
        "                    # print(f\"output[i][1] == {output[int(i)]}\")\n",
        "                    output.update({id : (data[str(id)][1] , [output[int(i)][0]] + output[int(i)][1] ) })\n",
        "                    # print(\"atualizou\")\n",
        "            except:\n",
        "                output.update({id : ( data[str(id)][1] , [] ) })\n",
        "        if up == True :\n",
        "            for i in str2list(data[str(id)][2]) :\n",
        "                up_catch_talk(data , int(i) , output , down = False )\n",
        "    except :\n",
        "        return\n",
        "\n",
        "dataSet = {}\n",
        "print(str2list(\"1 ,25,12,40\"))\n",
        "for id in list(cvv.keys())[1:] :\n",
        "    try :\n",
        "        id = int(id)\n",
        "        down_catch_talk(cvv , id ,dataSet)\n",
        "    except :\n",
        "        pass\n",
        "print(dataSet[1])\n",
        "# for i in range(1,15):\n",
        "#     print(cvv[str(i)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Du50-fkQE9QE"
      },
      "outputs": [],
      "source": [
        "print(dataSet[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6h-wnWTK49p"
      },
      "outputs": [],
      "source": [
        "a = {1:4,2:3,4:5}\n",
        "print(a)\n",
        "a.update({1:55})\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idUUlda31aaZ"
      },
      "outputs": [],
      "source": [
        "# path = \"/content/drive/MyDrive/Colab Notebooks/Chat_Bot.ipynb\"\n",
        "# !rsync -aP \"{path}\" /content/Chat_Bot\n",
        "\n",
        "# !git clone \"{Git_CB_Path}\" ./temp\n",
        "# !rsync -aP /content/Chat_Bot/* ./temp\n",
        "# %cd ./temp\n",
        "# !git add -u\n",
        "# !git commit -m \"update\"\n",
        "# !git config user.email \"limaalyson@hotmail.com\"\n",
        "# !git config user.name \"Alyson_Google_Colab\"\n",
        "# !git push origin master\n",
        "# %cd /content\n",
        "# !rm -rf ./temp\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Chat_Bot.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNwJj1V+NN5Qv+jtYqZZ4TW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}