{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chat_Bot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMylOGNsfUccrKjYL6VzwhJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toinnn/Chat_Bot/blob/master/Chat_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIg39CJSnDdg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "outputId": "3d620079-d4d3-4cfc-f0da-e0ad891a42e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting pyfora==0.4.2\n",
            "  Downloading pyfora-0.4.2.tar.gz (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting futures\n",
            "  Downloading futures-3.0.5.tar.gz (25 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/55/db/97c1ca37edab586a1ae03d6892b6633d8eaa23b23ac40c7e5bbc55423c78/futures-3.0.5.tar.gz#sha256=0542525145d5afc984c88f914a0c85c77527f65946617edb5274f72406f981df (from https://pypi.org/simple/futures/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading futures-3.0.4.tar.gz (25 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/8d/73/b5fff618482bc06c9711e7cdc0d5d7eb1904d35898f48f2d7f9696b08bef/futures-3.0.4.tar.gz#sha256=19485d83f7bd2151c0aeaf88fbba3ee50dadfb222ffc3b66a344ef4952b782a3 (from https://pypi.org/simple/futures/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading futures-3.0.3.tar.gz (24 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/4c/dc/f9473006d4c9c52d4a4e977173fbcbfb1a8ef3a57e32e885edf994fd4a45/futures-3.0.3.tar.gz#sha256=2fe2342bb4fe8b8e217f0d21b5921cbe5408bf966d9f92025e707e881b198bed (from https://pypi.org/simple/futures/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading futures-3.0.2.tar.gz (24 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/f8/e7/fc0fcbeb9193ba2d4de00b065e7fd5aecd0679e93ce95a07322b2b1434f4/futures-3.0.2.tar.gz#sha256=dc3fc91508e49e0fd2f8625f0132d16e49c80f882e7e1d565c56b0d5dfbae257 (from https://pypi.org/simple/futures/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading futures-3.0.1.tar.gz (24 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/b2/2c/6b6a57379e47031c6f52e625e0e2b8f6702a8d1f61b6e0daee391e82c187/futures-3.0.1.tar.gz#sha256=f78f2ef458639d72a625cf9c7643cf5442bb222ac11c12bcc445c6ad1cd862e2 (from https://pypi.org/simple/futures/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading futures-3.0.0.tar.gz (24 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/ea/c9/35287369718fc05059e7a9d0d73c53745fe981010b4185b3858e7d46eff1/futures-3.0.0.tar.gz#sha256=d9cd7bb09aa01f0e4940af64c31fbd7045098b7b4354420d7838ea39e8b86ee3 (from https://pypi.org/simple/futures/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading futures-2.2.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting socketIO-client>=0.6.5\n",
            "  Downloading socketIO-client-0.7.2.tar.gz (23 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyfora==0.4.2) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pyfora==0.4.2) (1.3.5)\n",
            "Collecting wsaccel\n",
            "  Downloading wsaccel-0.6.3.tar.gz (215 kB)\n",
            "\u001b[K     |████████████████████████████████| 215 kB 10.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from socketIO-client>=0.6.5->pyfora==0.4.2) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from socketIO-client>=0.6.5->pyfora==0.4.2) (1.15.0)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 972 kB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->socketIO-client>=0.6.5->pyfora==0.4.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->socketIO-client>=0.6.5->pyfora==0.4.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->socketIO-client>=0.6.5->pyfora==0.4.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->socketIO-client>=0.6.5->pyfora==0.4.2) (2021.10.8)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pyfora==0.4.2) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pyfora==0.4.2) (2.8.2)\n",
            "Building wheels for collected packages: pyfora, socketIO-client, wsaccel\n",
            "  Building wheel for pyfora (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfora: filename=pyfora-0.4.2-py3-none-any.whl size=186993 sha256=f1acdafef727ebf0fad6128897e3719dc489f66a4e19d84814c7f76205699b68\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/08/e2/e9d900eafcefe5acec8b155eb00ae5ad83c2b33dcb746b91d2\n",
            "  Building wheel for socketIO-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for socketIO-client: filename=socketIO_client-0.7.2-py3-none-any.whl size=23720 sha256=c16d50c36747bfbf8fd181738d9338a2d9b382969c4af209515b0999f8550ba6\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/4c/94/6e0d553c1ff6d3f7097b39143c888900af85a827fb929e647d\n",
            "  Building wheel for wsaccel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wsaccel: filename=wsaccel-0.6.3-cp37-cp37m-linux_x86_64.whl size=523603 sha256=5cb2da1af48c832b80e45da6e4db9aca1c39457237f3e7ee8cf6fc0fa4e9937c\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/7c/3c/8c54476b98995a0e64f1d70050963cf11bcf60c38ef6d3d303\n",
            "Successfully built pyfora socketIO-client wsaccel\n",
            "Installing collected packages: websocket-client, wsaccel, socketIO-client, futures, pyfora\n",
            "Successfully installed futures-2.2.0 pyfora-0.4.2 socketIO-client-0.7.2 websocket-client-1.2.3 wsaccel-0.6.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "concurrent"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()\n",
        "# !cat /proc/cpuinfo\n",
        "# !lscpu | grep 'Core(s) each processor has/per socket:'\n",
        "# !lscpu | grep 'Number of threads/core:'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwhJ0bhTGYi_",
        "outputId": "d7583931-115b-41a5-98b0-b54a56afc4cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Git_Dir    = \"/content/drive/MyDrive/Github_Dir/Chat_Bot\"\n",
        "Neural_Dir = \"Machine-Learning__Deep-Learning\"\n",
        "with open(\"/content/drive/MyDrive/Github_Dir/acess_Token_Git.txt\",\"r\") as file:\n",
        "    acess_Token_Git = file.read()\n",
        "Git_Path   = \"https://\"+ acess_Token_Git + \"@github.com/toinnn/\" + Neural_Dir + \".git\"\n",
        "Git_CB_Path= \"https://\"+ acess_Token_Git + \"@github.com/toinnn/\" + \"Chat_Bot\" + \".git\"\n",
        "%pip install jaro-winkler"
      ],
      "metadata": {
        "id": "FHFrjufquZPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"{Git_Path}\" ./temp/Machine-Learning__Deep-Learning\n",
        "!git clone \"{Git_CB_Path}\" ./temp/Chat_Bot\n",
        "\n",
        "!mv ./temp/* \"{Git_Dir}\"\n",
        "!rm -rf ./temp \n",
        "\n",
        "!rsync -aP \"{Git_Dir}\"/*  ./\n",
        "#!ln -s \"/content/drive/MyDrive/Github_Dir/Chat_Bot\" + Neural_Dir NLP"
      ],
      "metadata": {
        "id": "yxOPQqF2NNhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "from joblib import delayed, Parallel\n",
        "import jaro\n",
        "\n",
        "num_cores = multiprocessing.cpu_count()\n",
        "print(num_cores)\n",
        "\n",
        "def charNgram(text : str , n : int ) -> list:\n",
        "    text = text.split()\n",
        "    for word in text :\n",
        "        var = { word[i : i + j] : None  for i in range(0 ,len(word) -n + 1 , 1 )  for j in range(1 , n+1)    }\n",
        "        if len(word)%n != 0 :\n",
        "            falta = len(word)%n\n",
        "            var.update({ word[- falta :-i] : None for i in range(1 , falta)})\n",
        "            var.update({word[- falta :] : None})\n",
        "    # for word in text :\n",
        "    #     for i in range(0 ,len(word) -n + 1 , 1):#n\n",
        "    #         var.update({word[i : i + j] : None for j in range(1 , n+1) })\n",
        "    #     falta = len(word)%n\n",
        "    #     var.update({ word[- falta :-i] : None for i in range(1 , falta)})\n",
        "    #     var.update({word[- falta :] : None})\n",
        "\n",
        "    # var += [text[- (len(text)%n):]]\n",
        "    return list(var.keys())\n",
        "\n",
        "def jaroWinkler_Sort(nGram : list , n :int = None)-> tuple :\n",
        "    \n",
        "    if type(n) == type(1) :\n",
        "        try :\n",
        "            aux = {i :[] for i in range(1 , n + 1)}\n",
        "            for i in nGram :\n",
        "                aux[len(i)] += [i]\n",
        "            nGram = []\n",
        "            for i in list(aux.values() )[::-1] :\n",
        "                nGram += i\n",
        "        except :\n",
        "            print(\"Foi identificado que o n passado é menor que o usado na criação do nGram\")\n",
        "    for i in range(len(nGram) - 1 ) :\n",
        "        var = (jaro.original_metric(nGram[i] , nGram[i + 1] ) , nGram[i+1] ,i + 1 )\n",
        "        for j in range( i + 1,len(nGram)) :\n",
        "            if jaro.original_metric(nGram[i] , nGram[j] ) >  var[0] :\n",
        "                var = (jaro.original_metric(nGram[i] , nGram[j] ) , nGram[j] , j )\n",
        "        aux = nGram[i + 1]\n",
        "        nGram[i + 1] = var[1]\n",
        "        try :\n",
        "            nGram[var[2]]= aux\n",
        "        except :\n",
        "            print(j)\n",
        "        \n",
        "    return tuple(nGram)\n",
        "    # return nGram\n",
        "\n",
        "print(charNgram(\"cincocinsa\" , 4 ))\n",
        "print(jaroWinkler_Sort(charNgram(\"cincocinsa\" , 4 ) , 4 ))\n",
        "print(jaro.jaro_metric(\"abco\",\"bc\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOLkChh_deHk",
        "outputId": "5265cbb3-f8d5-44dc-a64e-db7e80c77bfe"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "['c', 'ci', 'cin', 'cinc', 'i', 'in', 'inc', 'inco', 'n', 'nc', 'nco', 'ncoc', 'co', 'coc', 'coci', 'o', 'oc', 'oci', 'ocin', 'cins', 'ins', 'insa', 's', 'sa']\n",
            "('cinc', 'cin', 'cins', 'ins', 'insa', 'in', 'inc', 'inco', 'nco', 'ncoc', 'coc', 'coci', 'co', 'c', 'ci', 'ocin', 'oci', 'oc', 'o', 'nc', 'n', 'i', 'sa', 's')\n",
            "0.8333333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/{Neural_Dir}\"\n",
        "from BiLSTM import BiLSTM ,BiLSTM_Attention\n",
        "%cd /content/Chat_Bot\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Rodei 123\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp7seqT8u9Ot",
        "outputId": "ce3bf4ca-35fb-45ec-9ab3-f6a7d572768b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Machine-Learning__Deep-Learning\n",
            "teste\n",
            "/content/Chat_Bot\n",
            "Rodei 123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path = \"/content/drive/MyDrive/Colab Notebooks/Chat_Bot.ipynb\"\n",
        "# !rsync -aP \"{path}\" /content/Chat_Bot\n",
        "\n",
        "# !git clone \"{Git_CB_Path}\" ./temp\n",
        "# !rsync -aP /content/Chat_Bot/* ./temp\n",
        "# %cd ./temp\n",
        "# !git add -u\n",
        "# !git commit -m \"update\"\n",
        "# !git config user.email \"limaalyson@hotmail.com\"\n",
        "# !git config user.name \"Alyson_Google_Colab\"\n",
        "# !git push origin master\n",
        "# %cd /content\n",
        "# !rm -rf ./temp\n"
      ],
      "metadata": {
        "id": "idUUlda31aaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50fd2dc0-3fb3-49dd-fab2-878113c46810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sending incremental file list\n",
            "Chat_Bot.ipynb\n",
            "\r          4,698 100%    0.00kB/s    0:00:00  \r          4,698 100%    0.00kB/s    0:00:00 (xfr#1, to-chk=0/1)\n",
            "Cloning into './temp'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 12 (delta 1), reused 6 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (12/12), done.\n",
            "sending incremental file list\n",
            "Chat_Bot.ipynb\n",
            "          4,698 100%    0.00kB/s    0:00:00 (xfr#1, to-chk=1/2)\n",
            "README.md\n",
            "             10 100%    9.77kB/s    0:00:00 (xfr#2, to-chk=0/2)\n",
            "/content/temp\n",
            "[master 0b8e7fd] update\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            " rewrite Chat_Bot.ipynb (95%)\n",
            "Counting objects: 3, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (3/3), done.\n",
            "Writing objects: 100% (3/3), 663 bytes | 663.00 KiB/s, done.\n",
            "Total 3 (delta 1), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/toinnn/Chat_Bot.git\n",
            "   9aed345..0b8e7fd  master -> master\n",
            "/content\n"
          ]
        }
      ]
    }
  ]
}