{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chat_Bot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP3hve99yIBepcI5KHdV0L8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toinnn/Chat_Bot/blob/master/Chat_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QIg39CJSnDdg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70fce5cf-a410-43a4-aa33-a532ef603d06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()\n",
        "!pip install pyspark py4j\n",
        "%pip install jaro-winkler\n",
        "# !cat /proc/cpuinfo\n",
        "# !lscpu | grep 'Core(s) each processor has/per socket:'\n",
        "# !lscpu | grep 'Number of threads/core:'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwhJ0bhTGYi_",
        "outputId": "f4e20304-79be-41df-9ade-bff6df2cf6b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 36 kB/s \n",
            "\u001b[?25hCollecting py4j\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 40.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=b1226ca88c752ab3101c5d7f351181b0c63b77345bac3f58a0b0783094ec8ac0\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n",
            "Collecting jaro-winkler\n",
            "  Downloading jaro_winkler-2.0.0-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: jaro-winkler\n",
            "Successfully installed jaro-winkler-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Git_Dir    = \"/content/drive/MyDrive/Github_Dir/Chat_Bot\"\n",
        "Neural_Dir = \"Machine-Learning__Deep-Learning\"\n",
        "with open(\"/content/drive/MyDrive/Github_Dir/acess_Token_Git.txt\",\"r\") as file:\n",
        "    acess_Token_Git = file.read()\n",
        "Git_Path   = \"https://\"+ acess_Token_Git + \"@github.com/toinnn/\" + Neural_Dir + \".git\"\n",
        "Git_CB_Path= \"https://\"+ acess_Token_Git + \"@github.com/toinnn/\" + \"Chat_Bot\" + \".git\""
      ],
      "metadata": {
        "id": "FHFrjufquZPT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"{Git_Path}\" ./temp/Machine-Learning__Deep-Learning\n",
        "!git clone \"{Git_CB_Path}\" ./temp/Chat_Bot\n",
        "\n",
        "!mv ./temp/* \"{Git_Dir}\"\n",
        "!rm -rf ./temp \n",
        "\n",
        "!rsync -aP \"{Git_Dir}\"/*  ./\n",
        "#!ln -s \"/content/drive/MyDrive/Github_Dir/Chat_Bot\" + Neural_Dir NLP"
      ],
      "metadata": {
        "id": "yxOPQqF2NNhE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c13b5c20-11a1-4097-b29a-9520ab5ab967"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into './temp/Machine-Learning__Deep-Learning'...\n",
            "remote: Enumerating objects: 524, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 524 (delta 8), reused 10 (delta 1), pack-reused 496\u001b[K\n",
            "Receiving objects: 100% (524/524), 49.56 MiB | 20.09 MiB/s, done.\n",
            "Resolving deltas: 100% (243/243), done.\n",
            "Cloning into './temp/Chat_Bot'...\n",
            "remote: Enumerating objects: 65, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 65 (delta 22), reused 18 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (65/65), done.\n",
            "mv: inter-device move failed: './temp/Chat_Bot' to '/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot'; unable to remove target: Directory not empty\n",
            "mv: inter-device move failed: './temp/Machine-Learning__Deep-Learning' to '/content/drive/MyDrive/Github_Dir/Chat_Bot/Machine-Learning__Deep-Learning'; unable to remove target: Directory not empty\n",
            "sending incremental file list\n",
            "Chat_Bot/\n",
            "Chat_Bot/Chat_Bot.ipynb\n",
            "          3,299 100%    0.00kB/s    0:00:00 (xfr#1, to-chk=285/288)\n",
            "Chat_Bot/README.md\n",
            "             10 100%    0.05kB/s    0:00:00 (xfr#2, to-chk=284/288)\n",
            "rsync: send_files failed to open \"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/teste (1).gsheet\": Operation not supported (95)\n",
            "Chat_Bot/teste.csv\n",
            "         11,663 100%   27.58kB/s    0:00:00 (xfr#4, to-chk=282/288)\n",
            "rsync: send_files failed to open \"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/teste.gsheet\": Operation not supported (95)\n",
            "Chat_Bot/.git/\n",
            "Chat_Bot/.git/HEAD\n",
            "             23 100%    0.03kB/s    0:00:00 (xfr#6, to-chk=276/288)\n",
            "Chat_Bot/.git/config\n",
            "            304 100%    0.37kB/s    0:00:00 (xfr#7, to-chk=275/288)\n",
            "Chat_Bot/.git/description\n",
            "             73 100%    0.06kB/s    0:00:01 (xfr#8, to-chk=274/288)\n",
            "Chat_Bot/.git/index\n",
            "            217 100%    0.17kB/s    0:00:01 (xfr#9, to-chk=273/288)\n",
            "Chat_Bot/.git/packed-refs\n",
            "            114 100%    0.08kB/s    0:00:01 (xfr#10, to-chk=272/288)\n",
            "Chat_Bot/.git/branches/\n",
            "Chat_Bot/.git/hooks/\n",
            "Chat_Bot/.git/hooks/applypatch-msg.sample\n",
            "            478 100%    0.00kB/s    0:00:00 (xfr#11, to-chk=265/288)\n",
            "Chat_Bot/.git/hooks/commit-msg.sample\n",
            "            896 100%    3.12kB/s    0:00:00 (xfr#12, to-chk=264/288)\n",
            "Chat_Bot/.git/hooks/fsmonitor-watchman.sample\n",
            "          3,327 100%    7.43kB/s    0:00:00 (xfr#13, to-chk=263/288)\n",
            "Chat_Bot/.git/hooks/post-update.sample\n",
            "            189 100%    0.29kB/s    0:00:00 (xfr#14, to-chk=262/288)\n",
            "Chat_Bot/.git/hooks/pre-applypatch.sample\n",
            "            424 100%    0.52kB/s    0:00:00 (xfr#15, to-chk=261/288)\n",
            "Chat_Bot/.git/hooks/pre-commit.sample\n",
            "          1,642 100%    1.65kB/s    0:00:00 (xfr#16, to-chk=260/288)\n",
            "Chat_Bot/.git/hooks/pre-push.sample\n",
            "          1,348 100%    1.08kB/s    0:00:01 (xfr#17, to-chk=259/288)\n",
            "Chat_Bot/.git/hooks/pre-rebase.sample\n",
            "          4,898 100%    3.36kB/s    0:00:01 (xfr#18, to-chk=258/288)\n",
            "Chat_Bot/.git/hooks/pre-receive.sample\n",
            "            544 100%    0.00kB/s    0:00:00 (xfr#19, to-chk=257/288)\n",
            "Chat_Bot/.git/hooks/prepare-commit-msg.sample\n",
            "          1,492 100%    9.11kB/s    0:00:00 (xfr#20, to-chk=256/288)\n",
            "Chat_Bot/.git/hooks/update.sample\n",
            "          3,610 100%    8.64kB/s    0:00:00 (xfr#21, to-chk=255/288)\n",
            "Chat_Bot/.git/info/\n",
            "Chat_Bot/.git/info/exclude\n",
            "            240 100%    0.39kB/s    0:00:00 (xfr#22, to-chk=254/288)\n",
            "Chat_Bot/.git/logs/\n",
            "Chat_Bot/.git/logs/HEAD\n",
            "            223 100%    0.29kB/s    0:00:00 (xfr#23, to-chk=253/288)\n",
            "Chat_Bot/.git/logs/refs/\n",
            "Chat_Bot/.git/logs/refs/heads/\n",
            "Chat_Bot/.git/logs/refs/heads/master\n",
            "            223 100%    0.25kB/s    0:00:00 (xfr#24, to-chk=249/288)\n",
            "Chat_Bot/.git/logs/refs/remotes/\n",
            "Chat_Bot/.git/logs/refs/remotes/origin/\n",
            "Chat_Bot/.git/logs/refs/remotes/origin/HEAD\n",
            "            223 100%    0.22kB/s    0:00:00 (xfr#25, to-chk=247/288)\n",
            "Chat_Bot/.git/objects/\n",
            "Chat_Bot/.git/objects/25/\n",
            "Chat_Bot/.git/objects/25/a921de47c254abfbfa2d7e64f488f5c5ca542f\n",
            "            184 100%    0.15kB/s    0:00:01 (xfr#26, to-chk=238/288)\n",
            "Chat_Bot/.git/objects/26/\n",
            "Chat_Bot/.git/objects/26/a35f7e049556b046d99a890d80b6441250f3f6\n",
            "          1,159 100%    0.77kB/s    0:00:01 (xfr#27, to-chk=237/288)\n",
            "Chat_Bot/.git/objects/52/\n",
            "Chat_Bot/.git/objects/52/0c30119bd35c98cb124c7be47d1489d7f44b63\n",
            "            519 100%    0.00kB/s    0:00:00 (xfr#28, to-chk=236/288)\n",
            "Chat_Bot/.git/objects/7a/\n",
            "Chat_Bot/.git/objects/7a/0cdddda78e49f26c5ad3399ed2bb33c46872ef\n",
            "             92 100%    0.59kB/s    0:00:00 (xfr#29, to-chk=235/288)\n",
            "Chat_Bot/.git/objects/ac/\n",
            "Chat_Bot/.git/objects/ac/b198f99a209cabc91d5fe67d8f70c72f7617ae\n",
            "             26 100%    0.09kB/s    0:00:00 (xfr#30, to-chk=234/288)\n",
            "Chat_Bot/.git/objects/b9/\n",
            "Chat_Bot/.git/objects/b9/9e3a8eb6481ee059fa4d1638dbcebd672d9101\n",
            "             54 100%    0.12kB/s    0:00:00 (xfr#31, to-chk=233/288)\n",
            "Chat_Bot/.git/objects/info/\n",
            "Chat_Bot/.git/objects/pack/\n",
            "Chat_Bot/.git/refs/\n",
            "Chat_Bot/.git/refs/heads/\n",
            "Chat_Bot/.git/refs/heads/master\n",
            "             41 100%    0.07kB/s    0:00:00 (xfr#32, to-chk=229/288)\n",
            "Chat_Bot/.git/refs/remotes/\n",
            "Chat_Bot/.git/refs/remotes/origin/\n",
            "Chat_Bot/.git/refs/remotes/origin/HEAD\n",
            "             32 100%    0.04kB/s    0:00:00 (xfr#33, to-chk=227/288)\n",
            "Chat_Bot/.git/refs/tags/\n",
            "Chat_Bot/Kaggle_Twitter_Custumer_Support__archive/\n",
            "Chat_Bot/Kaggle_Twitter_Custumer_Support__archive/sample.csv\n",
            "         17,357 100%   17.46kB/s    0:00:00 (xfr#34, to-chk=226/288)\n",
            "Chat_Bot/Kaggle_Twitter_Custumer_Support__archive/twcs/\n",
            "Chat_Bot/Kaggle_Twitter_Custumer_Support__archive/twcs/.~lock.twcs.csv#\n",
            "             94 100%    0.07kB/s    0:00:01 (xfr#35, to-chk=224/288)\n",
            "Chat_Bot/Kaggle_Twitter_Custumer_Support__archive/twcs/twcs.csv\n",
            "    516,508,641 100%   65.85MB/s    0:00:07 (xfr#36, to-chk=223/288)\n",
            "Chat_Bot/result3.csv/\n",
            "Chat_Bot/result3.csv/._SUCCESS.crc\n",
            "              8 100%    0.02kB/s    0:00:00 (xfr#37, to-chk=222/288)\n",
            "Chat_Bot/result3.csv/.part-00000-ad8dde7b-bbb4-41a6-b995-9a723a37e71b-c000.csv.crc\n",
            "      3,979,900 100%    5.19MB/s    0:00:00 (xfr#38, to-chk=221/288)\n",
            "Chat_Bot/result3.csv/_SUCCESS\n",
            "              0 100%    0.00kB/s    0:00:00 (xfr#39, to-chk=220/288)\n",
            "Chat_Bot/result3.csv/part-00000-ad8dde7b-bbb4-41a6-b995-9a723a37e71b-c000.csv\n",
            "    509,426,060 100%   65.63MB/s    0:00:07 (xfr#40, to-chk=219/288)\n",
            "Chat_Bot/teste/\n",
            "Chat_Bot/teste/._SUCCESS.crc\n",
            "              8 100%    0.01kB/s    0:00:00 (xfr#41, to-chk=218/288)\n",
            "Chat_Bot/teste/.part-00000-112eaf24-cef8-423b-8389-7edc8a1b9ab9-c000.csv.crc\n",
            "             40 100%    0.05kB/s    0:00:00 (xfr#42, to-chk=217/288)\n",
            "Chat_Bot/teste/.part-00001-112eaf24-cef8-423b-8389-7edc8a1b9ab9-c000.csv.crc\n",
            "             20 100%    0.02kB/s    0:00:00 (xfr#43, to-chk=216/288)\n",
            "Chat_Bot/teste/.part-00002-112eaf24-cef8-423b-8389-7edc8a1b9ab9-c000.csv.crc\n",
            "             48 100%    0.04kB/s    0:00:01 (xfr#44, to-chk=215/288)\n",
            "Chat_Bot/teste/.part-00003-112eaf24-cef8-423b-8389-7edc8a1b9ab9-c000.csv.crc\n",
            "             24 100%    0.02kB/s    0:00:01 (xfr#45, to-chk=214/288)\n",
            "Chat_Bot/teste/_SUCCESS\n",
            "              0 100%    0.00kB/s    0:00:00 (xfr#46, to-chk=213/288)\n",
            "Chat_Bot/teste/part-00000-112eaf24-cef8-423b-8389-7edc8a1b9ab9-c000.csv\n",
            "          3,621 100%    2.50kB/s    0:00:01 (xfr#47, to-chk=212/288)\n",
            "Chat_Bot/teste/part-00001-112eaf24-cef8-423b-8389-7edc8a1b9ab9-c000.csv\n",
            "          1,253 100%    0.00kB/s    0:00:00 (xfr#48, to-chk=211/288)\n",
            "Chat_Bot/teste/part-00002-112eaf24-cef8-423b-8389-7edc8a1b9ab9-c000.csv\n",
            "          4,759 100%   29.60kB/s    0:00:00 (xfr#49, to-chk=210/288)\n",
            "Chat_Bot/teste/part-00003-112eaf24-cef8-423b-8389-7edc8a1b9ab9-c000.csv\n",
            "          2,030 100%    7.03kB/s    0:00:00 (xfr#50, to-chk=209/288)\n",
            "Machine-Learning__Deep-Learning/\n",
            "Machine-Learning__Deep-Learning/.gitattributes\n",
            "             66 100%    0.12kB/s    0:00:00 (xfr#51, to-chk=208/288)\n",
            "Machine-Learning__Deep-Learning/.gitignore\n",
            "            205 100%    0.30kB/s    0:00:00 (xfr#52, to-chk=207/288)\n",
            "Machine-Learning__Deep-Learning/BiGRU.py\n",
            "         12,920 100%   15.46kB/s    0:00:00 (xfr#53, to-chk=206/288)\n",
            "Machine-Learning__Deep-Learning/BiLSTM.py\n",
            "         30,417 100%   28.59kB/s    0:00:01 (xfr#54, to-chk=205/288)\n",
            "Machine-Learning__Deep-Learning/README.md\n",
            "          1,028 100%    0.84kB/s    0:00:01 (xfr#55, to-chk=204/288)\n",
            "Machine-Learning__Deep-Learning/Tener.py\n",
            "         14,346 100%   10.04kB/s    0:00:01 (xfr#56, to-chk=203/288)\n",
            "Machine-Learning__Deep-Learning/workspace.code-workspace\n",
            "            165 100%    0.00kB/s    0:00:00 (xfr#57, to-chk=202/288)\n",
            "Machine-Learning__Deep-Learning/.git/\n",
            "Machine-Learning__Deep-Learning/.git/HEAD\n",
            "             23 100%    0.13kB/s    0:00:00 (xfr#58, to-chk=199/288)\n",
            "Machine-Learning__Deep-Learning/.git/config\n",
            "            327 100%    1.09kB/s    0:00:00 (xfr#59, to-chk=198/288)\n",
            "Machine-Learning__Deep-Learning/.git/description\n",
            "             73 100%    0.15kB/s    0:00:00 (xfr#60, to-chk=197/288)\n",
            "Machine-Learning__Deep-Learning/.git/index\n",
            "         22,160 100%   37.38kB/s    0:00:00 (xfr#61, to-chk=196/288)\n",
            "Machine-Learning__Deep-Learning/.git/packed-refs\n",
            "            114 100%    0.15kB/s    0:00:00 (xfr#62, to-chk=195/288)\n",
            "Machine-Learning__Deep-Learning/.git/branches/\n",
            "Machine-Learning__Deep-Learning/.git/hooks/\n",
            "Machine-Learning__Deep-Learning/.git/hooks/applypatch-msg.sample\n",
            "            478 100%    0.49kB/s    0:00:00 (xfr#63, to-chk=188/288)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/commit-msg.sample\n",
            "            896 100%    0.80kB/s    0:00:01 (xfr#64, to-chk=187/288)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/fsmonitor-watchman.sample\n",
            "          3,327 100%    2.52kB/s    0:00:01 (xfr#65, to-chk=186/288)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/post-update.sample\n",
            "            189 100%    0.13kB/s    0:00:01 (xfr#66, to-chk=185/288)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/pre-applypatch.sample\n",
            "            424 100%    0.00kB/s    0:00:00 (xfr#67, to-chk=184/288)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/pre-commit.sample\n",
            "          1,642 100%   11.97kB/s    0:00:00 (xfr#68, to-chk=183/288)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/pre-push.sample\n",
            "          1,348 100%    3.80kB/s    0:00:00 (xfr#69, to-chk=182/288)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/pre-rebase.sample\n",
            "          4,898 100%    9.38kB/s    0:00:00 (xfr#70, to-chk=181/288)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/pre-receive.sample\n",
            "            544 100%    0.68kB/s    0:00:00 (xfr#71, to-chk=180/288)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/prepare-commit-msg.sample\n",
            "          1,492 100%    1.49kB/s    0:00:00 (xfr#72, to-chk=179/288)\n",
            "Machine-Learning__Deep-Learning/.git/hooks/update.sample\n",
            "          3,610 100%    2.98kB/s    0:00:01 (xfr#73, to-chk=178/288)\n",
            "Machine-Learning__Deep-Learning/.git/info/\n",
            "Machine-Learning__Deep-Learning/.git/info/exclude\n",
            "            240 100%    0.18kB/s    0:00:01 (xfr#74, to-chk=177/288)\n",
            "Machine-Learning__Deep-Learning/.git/logs/\n",
            "Machine-Learning__Deep-Learning/.git/logs/HEAD\n",
            "            246 100%    0.17kB/s    0:00:01 (xfr#75, to-chk=176/288)\n",
            "Machine-Learning__Deep-Learning/.git/logs/refs/\n",
            "Machine-Learning__Deep-Learning/.git/logs/refs/heads/\n",
            "Machine-Learning__Deep-Learning/.git/logs/refs/heads/master\n",
            "            246 100%    0.00kB/s    0:00:00 (xfr#76, to-chk=172/288)\n",
            "Machine-Learning__Deep-Learning/.git/logs/refs/remotes/\n",
            "Machine-Learning__Deep-Learning/.git/logs/refs/remotes/origin/\n",
            "Machine-Learning__Deep-Learning/.git/logs/refs/remotes/origin/HEAD\n",
            "            246 100%    1.95kB/s    0:00:00 (xfr#77, to-chk=170/288)\n",
            "Machine-Learning__Deep-Learning/.git/objects/\n",
            "Machine-Learning__Deep-Learning/.git/objects/info/\n",
            "Machine-Learning__Deep-Learning/.git/objects/pack/\n",
            "Machine-Learning__Deep-Learning/.git/objects/pack/pack-f79357c92226a6acdbf8ce1883b4f8afe6463e73.idx\n",
            "         15,744 100%   56.94kB/s    0:00:00 (xfr#78, to-chk=167/288)\n",
            "Machine-Learning__Deep-Learning/.git/objects/pack/pack-f79357c92226a6acdbf8ce1883b4f8afe6463e73.pack\n",
            "     51,965,768 100%   43.93MB/s    0:00:01 (xfr#79, to-chk=166/288)\n",
            "Machine-Learning__Deep-Learning/.git/refs/\n",
            "Machine-Learning__Deep-Learning/.git/refs/heads/\n",
            "Machine-Learning__Deep-Learning/.git/refs/heads/master\n",
            "             41 100%    0.13kB/s    0:00:00 (xfr#80, to-chk=162/288)\n",
            "Machine-Learning__Deep-Learning/.git/refs/remotes/\n",
            "Machine-Learning__Deep-Learning/.git/refs/remotes/origin/\n",
            "Machine-Learning__Deep-Learning/.git/refs/remotes/origin/HEAD\n",
            "             32 100%    0.06kB/s    0:00:00 (xfr#81, to-chk=160/288)\n",
            "Machine-Learning__Deep-Learning/.git/refs/tags/\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/1-n=0.005_dim=30_maxAge=1_momentum=0.01_maxErro=0.005.savedSkipGram\n",
            "     23,456,083 100%   19.15MB/s    0:00:01 (xfr#82, to-chk=159/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/1-n=0.005_dim=30_maxAge=2_momentum=0.01_maxErro=0.005.savedSkipGram\n",
            "     23,456,083 100%   34.68MB/s    0:00:00 (xfr#83, to-chk=158/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/Ner_Test.py\n",
            "         10,061 100%   12.06kB/s    0:00:00 (xfr#84, to-chk=157/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/ark_Target_Test_W2Vec.pickle\n",
            "          6,167 100%    5.96kB/s    0:00:01 (xfr#85, to-chk=156/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/ark_Target_W2Vec.pickle\n",
            "         15,185 100%   13.19kB/s    0:00:01 (xfr#86, to-chk=155/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/ark_Test_W2Vec.pickle\n",
            "     23,254,529 100%   14.09MB/s    0:00:01 (xfr#87, to-chk=154/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/ark_W2Vec.pickle\n",
            "     67,820,763 100%   40.22MB/s    0:00:01 (xfr#88, to-chk=153/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/classesTarget_Entity_materias_W2Vec.pickle\n",
            "            341 100%    0.47kB/s    0:00:00 (xfr#89, to-chk=152/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/skip_Gram.py\n",
            "         11,402 100%   11.62kB/s    0:00:00 (xfr#90, to-chk=151/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/.vscode/\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/.vscode/settings.json\n",
            "             70 100%    0.06kB/s    0:00:01 (xfr#91, to-chk=147/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/__pycache__/\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/__pycache__/BiLSTM.cpython-38.pyc\n",
            "         15,961 100%   12.23kB/s    0:00:01 (xfr#92, to-chk=146/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/__pycache__/Tener.cpython-38.pyc\n",
            "         12,266 100%    8.39kB/s    0:00:01 (xfr#93, to-chk=145/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/__pycache__/skip_Gram.cpython-38.pyc\n",
            "          8,643 100%    0.00kB/s    0:00:00 (xfr#94, to-chk=144/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/airr8014220212_meta.json\n",
            "          2,270 100%   16.79kB/s    0:00:00 (xfr#95, to-chk=143/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/desktop.ini\n",
            "             74 100%    0.25kB/s    0:00:00 (xfr#96, to-chk=142/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/20150110436469APC_meta.json\n",
            "          1,396 100%    3.26kB/s    0:00:00 (xfr#97, to-chk=139/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AC10024133855890001_meta.json\n",
            "          3,330 100%    5.59kB/s    0:00:00 (xfr#98, to-chk=138/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AC1TCU_meta.json\n",
            "          5,027 100%    6.92kB/s    0:00:00 (xfr#99, to-chk=137/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AC1TJAC_meta.json\n",
            "          2,970 100%    3.14kB/s    0:00:00 (xfr#100, to-chk=136/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AC1TJMG_meta.json\n",
            "          3,153 100%    2.78kB/s    0:00:01 (xfr#101, to-chk=135/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AC20150110436469APC_meta.json\n",
            "          1,201 100%    0.91kB/s    0:00:01 (xfr#102, to-chk=134/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/ACO2821STF_meta.json\n",
            "          1,281 100%    0.84kB/s    0:00:01 (xfr#103, to-chk=133/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/ACORDAOTCU11602016_meta.json\n",
            "          1,883 100%    0.00kB/s    0:00:00 (xfr#104, to-chk=132/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/ACORDAOTCU25052016_meta.json\n",
            "          1,635 100%    6.12kB/s    0:00:00 (xfr#105, to-chk=131/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/ADI1TJDFT_meta.json\n",
            "          2,141 100%    4.08kB/s    0:00:00 (xfr#106, to-chk=130/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/ADI2TJDFT_meta.json\n",
            "          1,122 100%    1.47kB/s    0:00:00 (xfr#107, to-chk=129/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AIAgRAgI6193ARAGUARIMG_meta.json\n",
            "          2,458 100%    2.56kB/s    0:00:00 (xfr#108, to-chk=128/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AIRR10006691020135020322_meta.json\n",
            "          3,473 100%    3.06kB/s    0:00:01 (xfr#109, to-chk=127/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AIRR15708820115050222_meta.json\n",
            "          1,987 100%    1.54kB/s    0:00:01 (xfr#110, to-chk=126/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AIRR285001420095060020_meta.json\n",
            "            888 100%    0.62kB/s    0:00:01 (xfr#111, to-chk=125/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AIRR3731820145060141_meta.json\n",
            "          3,895 100%    0.00kB/s    0:00:00 (xfr#112, to-chk=124/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AIRR3999520145020086_meta.json\n",
            "            820 100%    3.53kB/s    0:00:00 (xfr#113, to-chk=123/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AIRR581406820065030079_meta.json\n",
            "            947 100%    2.14kB/s    0:00:00 (xfr#114, to-chk=122/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AP00000794920137060006_meta.json\n",
            "          2,252 100%    3.43kB/s    0:00:00 (xfr#115, to-chk=121/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AP00001415620157010201_meta.json\n",
            "          2,343 100%    2.99kB/s    0:00:00 (xfr#116, to-chk=120/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AP00001441420167030203_meta.json\n",
            "          2,521 100%    2.65kB/s    0:00:00 (xfr#117, to-chk=119/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AP771420167080008PA_meta.json\n",
            "          1,733 100%    1.61kB/s    0:00:01 (xfr#118, to-chk=118/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/APO1TJDFT_meta.json\n",
            "          2,485 100%    1.96kB/s    0:00:01 (xfr#119, to-chk=117/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/Ag10000170733596001_meta.json\n",
            "          1,550 100%    1.11kB/s    0:00:01 (xfr#120, to-chk=116/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/Ag10105170208398001_meta.json\n",
            "            700 100%    0.00kB/s    0:00:00 (xfr#121, to-chk=115/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AgAIRR11889820145030011_meta.json\n",
            "          1,540 100%   12.03kB/s    0:00:00 (xfr#122, to-chk=114/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AgAIRR617420125150072_meta.json\n",
            "          1,299 100%    4.96kB/s    0:00:00 (xfr#123, to-chk=113/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AgCr10582160008758001_meta.json\n",
            "          1,033 100%    2.52kB/s    0:00:00 (xfr#124, to-chk=112/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AgRg1STM_meta.json\n",
            "          1,772 100%    3.12kB/s    0:00:00 (xfr#125, to-chk=111/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AgRgSTJ1_meta.json\n",
            "          1,506 100%    2.16kB/s    0:00:00 (xfr#126, to-chk=110/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AgRgSTJ2_meta.json\n",
            "          4,414 100%    5.29kB/s    0:00:00 (xfr#127, to-chk=109/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AgRgTSE1_meta.json\n",
            "            976 100%    1.00kB/s    0:00:00 (xfr#128, to-chk=108/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/AgRgTSE3_meta.json\n",
            "          1,606 100%    1.42kB/s    0:00:01 (xfr#129, to-chk=107/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/Agr10540170008341001_meta.json\n",
            "          1,384 100%    1.11kB/s    0:00:01 (xfr#130, to-chk=106/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/CP32320177080008PA_meta.json\n",
            "          2,393 100%    1.70kB/s    0:00:01 (xfr#131, to-chk=105/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/DespSEPLAGDF_meta.json\n",
            "            285 100%    0.00kB/s    0:00:00 (xfr#132, to-chk=104/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/ED1STM_meta.json\n",
            "          1,710 100%   12.95kB/s    0:00:00 (xfr#133, to-chk=103/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/ED1TJAC_meta.json\n",
            "          2,088 100%    7.81kB/s    0:00:00 (xfr#134, to-chk=102/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/EDAgRgTSE2_meta.json\n",
            "          2,241 100%    5.39kB/s    0:00:00 (xfr#135, to-chk=101/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/EDEDARR208420135040232_meta.json\n",
            "          1,866 100%    3.42kB/s    0:00:00 (xfr#136, to-chk=100/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/EDRR1TST_meta.json\n",
            "            840 100%    1.25kB/s    0:00:00 (xfr#137, to-chk=99/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/EEDRR9715120105020002_meta.json\n",
            "          2,849 100%    3.51kB/s    0:00:00 (xfr#138, to-chk=98/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/ERR731004520105130003_meta.json\n",
            "          9,321 100%    9.89kB/s    0:00:00 (xfr#139, to-chk=97/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/HC04798525420128130000_meta.json\n",
            "          4,928 100%    4.14kB/s    0:00:01 (xfr#140, to-chk=96/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/HC10000150589281000_meta.json\n",
            "          3,360 100%    2.42kB/s    0:00:01 (xfr#141, to-chk=95/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/HC10000170833503000_meta.json\n",
            "          1,742 100%    0.00kB/s    0:00:00 (xfr#142, to-chk=94/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/HC110260SP_meta.json\n",
            "          4,221 100%   27.30kB/s    0:00:00 (xfr#143, to-chk=93/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/HC151914AgRES_meta.json\n",
            "          1,296 100%    4.38kB/s    0:00:00 (xfr#144, to-chk=92/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/HC340624SP_meta.json\n",
            "          2,552 100%    5.80kB/s    0:00:00 (xfr#145, to-chk=91/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/HC418951PR_meta.json\n",
            "            467 100%    0.82kB/s    0:00:00 (xfr#146, to-chk=90/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/HC70000692720177000000_meta.json\n",
            "          2,001 100%    2.74kB/s    0:00:00 (xfr#147, to-chk=89/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/HC70000845920187000000_meta.json\n",
            "          1,219 100%    1.18kB/s    0:00:01 (xfr#148, to-chk=88/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/INSTRUCAOON06043378120186000000_meta.json\n",
            "            659 100%    0.55kB/s    0:00:01 (xfr#149, to-chk=87/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/Lei11788_meta.json\n",
            "            694 100%    0.49kB/s    0:00:01 (xfr#150, to-chk=86/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/LoaDF2018_meta.json\n",
            "            257 100%    0.00kB/s    0:00:00 (xfr#151, to-chk=85/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/Pet128TSE5_meta.json\n",
            "          1,350 100%    6.34kB/s    0:00:00 (xfr#152, to-chk=84/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/Port77DF_meta.json\n",
            "            499 100%    1.43kB/s    0:00:00 (xfr#153, to-chk=83/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/REE5908TSE4_meta.json\n",
            "          4,897 100%    9.14kB/s    0:00:00 (xfr#154, to-chk=82/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/REsp1583083RS_meta.json\n",
            "          4,740 100%    6.58kB/s    0:00:00 (xfr#155, to-chk=81/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/RR-578030-46.1999.5.04.0018_meta.json\n",
            "          3,504 100%    4.11kB/s    0:00:00 (xfr#156, to-chk=80/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/RR14976020105020085_meta.json\n",
            "          3,156 100%    3.07kB/s    0:00:01 (xfr#157, to-chk=79/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/RR2574407120025020372_meta.json\n",
            "          8,649 100%    7.44kB/s    0:00:01 (xfr#158, to-chk=78/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/RR474820145230056_meta.json\n",
            "            880 100%    0.68kB/s    0:00:01 (xfr#159, to-chk=77/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/RR942006420095040028_meta.json\n",
            "          3,232 100%    2.27kB/s    0:00:01 (xfr#160, to-chk=76/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/Rcl3495STJ_meta.json\n",
            "          1,721 100%    0.00kB/s    0:00:00 (xfr#161, to-chk=75/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/TCU4687_meta.json\n",
            "          4,583 100%   34.97kB/s    0:00:00 (xfr#162, to-chk=74/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/TSTRR16037920105200001_meta.json\n",
            "          2,712 100%   10.43kB/s    0:00:00 (xfr#163, to-chk=73/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/adi3767_meta.json\n",
            "          1,030 100%    2.73kB/s    0:00:00 (xfr#164, to-chk=72/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/airr801422012_meta.json\n",
            "          1,883 100%    3.64kB/s    0:00:00 (xfr#165, to-chk=71/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/Json-Ner/lei11340_meta.json\n",
            "            733 100%    1.03kB/s    0:00:00 (xfr#166, to-chk=70/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/20150110436469APC.txt\n",
            "         10,793 100%   11.60kB/s    0:00:00 (xfr#167, to-chk=69/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AC10024133855890001.txt\n",
            "         18,477 100%   17.09kB/s    0:00:01 (xfr#168, to-chk=68/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AC1TCU.txt\n",
            "         36,860 100%   28.14kB/s    0:00:01 (xfr#169, to-chk=67/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AC1TJAC.txt\n",
            "         40,518 100%  324.33kB/s    0:00:00 (xfr#170, to-chk=66/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AC1TJMG.txt\n",
            "         19,952 100%   72.16kB/s    0:00:00 (xfr#171, to-chk=65/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AC20150110436469APC.txt\n",
            "          9,580 100%   22.93kB/s    0:00:00 (xfr#172, to-chk=64/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/ACO2821STF.txt\n",
            "         64,656 100%  117.36kB/s    0:00:00 (xfr#173, to-chk=63/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/ACORDAOTCU11602016.txt\n",
            "        135,006 100%  198.26kB/s    0:00:00 (xfr#174, to-chk=62/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/ACORDAOTCU25052016.txt\n",
            "         45,125 100%   48.53kB/s    0:00:00 (xfr#175, to-chk=61/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/ADI1TJDFT.txt\n",
            "         92,043 100%   77.22kB/s    0:00:01 (xfr#176, to-chk=60/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/ADI2TJDFT.txt\n",
            "         59,003 100%  277.02kB/s    0:00:00 (xfr#177, to-chk=59/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AIAgRAgI6193ARAGUARIMG.txt\n",
            "         17,078 100%   37.73kB/s    0:00:00 (xfr#178, to-chk=58/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AIRR10006691020135020322.txt\n",
            "         16,091 100%   23.95kB/s    0:00:00 (xfr#179, to-chk=57/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AIRR15708820115050222.txt\n",
            "         34,952 100%   43.87kB/s    0:00:00 (xfr#180, to-chk=56/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AIRR285001420095060020.txt\n",
            "          7,927 100%    7.94kB/s    0:00:00 (xfr#181, to-chk=55/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AIRR3731820145060141.txt\n",
            "         21,951 100%   18.38kB/s    0:00:01 (xfr#182, to-chk=54/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AIRR3999520145020086.txt\n",
            "          5,664 100%    4.31kB/s    0:00:01 (xfr#183, to-chk=53/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AIRR581406820065030079.txt\n",
            "          8,343 100%    5.76kB/s    0:00:01 (xfr#184, to-chk=52/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AP00000794920137060006.txt\n",
            "         44,306 100%   11.00MB/s    0:00:00 (xfr#185, to-chk=51/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AP00001415620157010201.txt\n",
            "         25,977 100%  187.91kB/s    0:00:00 (xfr#186, to-chk=50/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AP00001441420167030203.txt\n",
            "        135,590 100%  462.98kB/s    0:00:00 (xfr#187, to-chk=49/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AP771420167080008PA.txt\n",
            "         13,983 100%   26.16kB/s    0:00:00 (xfr#188, to-chk=48/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/APO1TJDFT.txt\n",
            "         22,924 100%   31.22kB/s    0:00:00 (xfr#189, to-chk=47/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/Ag10000170733596001.txt\n",
            "          8,281 100%    8.61kB/s    0:00:00 (xfr#190, to-chk=46/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/Ag10105170208398001.txt\n",
            "          6,774 100%    6.17kB/s    0:00:01 (xfr#191, to-chk=45/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AgAIRR11889820145030011.txt\n",
            "         10,794 100%    8.04kB/s    0:00:01 (xfr#192, to-chk=44/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AgAIRR617420125150072.txt\n",
            "          8,723 100%    5.90kB/s    0:00:01 (xfr#193, to-chk=43/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AgCr10582160008758001.txt\n",
            "         16,878 100%    0.00kB/s    0:00:00 (xfr#194, to-chk=42/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AgRg1STM.txt\n",
            "         15,001 100%  125.21kB/s    0:00:00 (xfr#195, to-chk=41/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AgRgSTJ1.txt\n",
            "         13,675 100%   52.17kB/s    0:00:00 (xfr#196, to-chk=40/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AgRgSTJ2.txt\n",
            "         29,636 100%   71.64kB/s    0:00:00 (xfr#197, to-chk=39/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AgRgTSE1.txt\n",
            "         18,913 100%   34.98kB/s    0:00:00 (xfr#198, to-chk=38/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/AgRgTSE3.txt\n",
            "         34,422 100%   51.96kB/s    0:00:00 (xfr#199, to-chk=37/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/Agr10540170008341001.txt\n",
            "          8,199 100%   10.25kB/s    0:00:00 (xfr#200, to-chk=36/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/CP32320177080008PA.txt\n",
            "         16,135 100%   17.26kB/s    0:00:00 (xfr#201, to-chk=35/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/DespSEPLAGDF.txt\n",
            "         13,017 100%   10.67kB/s    0:00:01 (xfr#202, to-chk=34/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/ED1STM.txt\n",
            "         19,102 100%   13.95kB/s    0:00:01 (xfr#203, to-chk=33/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/ED1TJAC.txt\n",
            "         27,151 100%   18.22kB/s    0:00:01 (xfr#204, to-chk=32/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/EDAgRgTSE2.txt\n",
            "         11,025 100%    0.00kB/s    0:00:00 (xfr#205, to-chk=31/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/EDEDARR208420135040232.txt\n",
            "          8,468 100%   38.46kB/s    0:00:00 (xfr#206, to-chk=30/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/EDRR1TST.txt\n",
            "         10,686 100%   30.87kB/s    0:00:00 (xfr#207, to-chk=29/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/EEDRR9715120105020002.txt\n",
            "         31,100 100%   60.62kB/s    0:00:00 (xfr#208, to-chk=28/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/ERR731004520105130003.txt\n",
            "         55,918 100%   80.31kB/s    0:00:00 (xfr#209, to-chk=27/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/HC04798525420128130000.txt\n",
            "         22,249 100%   26.53kB/s    0:00:00 (xfr#210, to-chk=26/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/HC10000150589281000.txt\n",
            "         14,893 100%   14.30kB/s    0:00:01 (xfr#211, to-chk=25/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/HC10000170833503000.txt\n",
            "         13,011 100%   10.80kB/s    0:00:01 (xfr#212, to-chk=24/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/HC110260SP.txt\n",
            "         83,130 100%   57.29kB/s    0:00:01 (xfr#213, to-chk=23/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/HC151914AgRES.txt\n",
            "         21,614 100%   83.10kB/s    0:00:00 (xfr#214, to-chk=22/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/HC340624SP.txt\n",
            "         23,529 100%   60.31kB/s    0:00:00 (xfr#215, to-chk=21/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/HC418951PR.txt\n",
            "          7,990 100%   15.67kB/s    0:00:00 (xfr#216, to-chk=20/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/HC70000692720177000000.txt\n",
            "         21,415 100%   31.64kB/s    0:00:00 (xfr#217, to-chk=19/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/HC70000845920187000000.txt\n",
            "         16,059 100%   18.80kB/s    0:00:00 (xfr#218, to-chk=18/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/INSTRUCAOON06043378120186000000.txt\n",
            "          2,213 100%    2.24kB/s    0:00:00 (xfr#219, to-chk=17/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/Lei11788.txt\n",
            "         17,658 100%   15.47kB/s    0:00:01 (xfr#220, to-chk=16/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/LoaDF2018.txt\n",
            "          6,201 100%    4.79kB/s    0:00:01 (xfr#221, to-chk=15/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/Pet128TSE5.txt\n",
            "         16,322 100%   11.44kB/s    0:00:01 (xfr#222, to-chk=14/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/Port77DF.txt\n",
            "          3,859 100%    0.00kB/s    0:00:00 (xfr#223, to-chk=13/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/REE5908TSE4.txt\n",
            "         40,098 100%  207.19kB/s    0:00:00 (xfr#224, to-chk=12/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/REsp1583083RS.txt\n",
            "         34,833 100%   89.52kB/s    0:00:00 (xfr#225, to-chk=11/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/RR-578030-46.1999.5.04.0018.txt\n",
            "         23,391 100%   40.43kB/s    0:00:00 (xfr#226, to-chk=10/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/RR14976020105020085.txt\n",
            "         35,635 100%   43.23kB/s    0:00:00 (xfr#227, to-chk=9/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/RR2574407120025020372.txt\n",
            "         47,510 100%   46.77kB/s    0:00:00 (xfr#228, to-chk=8/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/RR474820145230056.txt\n",
            "          2,686 100%    2.19kB/s    0:00:01 (xfr#229, to-chk=7/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/RR942006420095040028.txt\n",
            "         35,498 100%   23.84kB/s    0:00:01 (xfr#230, to-chk=6/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/Rcl3495STJ.txt\n",
            "         13,408 100%   96.99kB/s    0:00:00 (xfr#231, to-chk=5/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/TCU4687.txt\n",
            "         27,620 100%   97.02kB/s    0:00:00 (xfr#232, to-chk=4/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/TSTRR16037920105200001.txt\n",
            "         89,515 100%  181.74kB/s    0:00:00 (xfr#233, to-chk=3/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/adi3767.txt\n",
            "         30,898 100%   43.86kB/s    0:00:00 (xfr#234, to-chk=2/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/airr801422012.txt\n",
            "         20,016 100%   22.49kB/s    0:00:00 (xfr#235, to-chk=1/288)\n",
            "Machine-Learning__Deep-Learning/NLP_NamedEntityRecognition/leNer-Dataset/raw-Text/lei11340.txt\n",
            "         34,566 100%   31.43kB/s    0:00:01 (xfr#236, to-chk=0/288)\n",
            "rsync error: some files/attrs were not transferred (see previous errors) (code 23) at main.c(1196) [sender=3.1.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jaro\n",
        "# !jupyter notebook --generate-config\n",
        "$jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000\n",
        "# %notebook Chat_Bot.ipynb --NotebookApp.iopub_data_rate_limit=1.0e10\n",
        "# $ jupyter notebook --generate-config\n",
        "\n",
        "class nGram_Utils():\n",
        "    def __init__(self):\n",
        "        self.nGram = []\n",
        "        self.nGram2idx = None\n",
        "        self.n = None\n",
        "    def prepare_Text(self , text : str , n : int):\n",
        "        self.nGram = self.charNgram(text , n )\n",
        "        self.nGram = self.jaroWinkler_Sort(self.nGram , n )\n",
        "        \n",
        "        self.nGram2idx = {self.nGram[i] : i  for i in range(len(self.nGram))}\n",
        "        self.nGram2idx[\" \"] = len(self.nGram)\n",
        "\n",
        "        # return self.text2idx(text , self.nGram2idx , n )\n",
        "        \n",
        "    def charNgram(self ,text : str , n : int ) -> list:\n",
        "        text = text.split()\n",
        "        for word in text :\n",
        "            var = { word[i : i + j] : None  for i in range(0 ,len(word) -n + 1 , 1 )  for j in range(1 , n+1)    }\n",
        "            if len(word)%n != 0 :\n",
        "                falta = len(word)%n\n",
        "                var.update({ word[- falta :-i] : None for i in range(1 , falta)})\n",
        "                var.update({word[- falta :] : None})\n",
        "        \n",
        "        return list(var.keys())\n",
        "\n",
        "    def jaroWinkler_Sort(self ,nGram : list , n :int = None)-> tuple :\n",
        "        \n",
        "        if type(n) == type(1) :\n",
        "            try :\n",
        "                aux = {i :[] for i in range(1 , n + 1)}\n",
        "                for i in nGram :\n",
        "                    aux[len(i)] += [i]\n",
        "                nGram = []\n",
        "                for i in list(aux.values() )[::-1] :\n",
        "                    nGram += i\n",
        "            except :\n",
        "                print(\"Foi identificado que o n passado é menor que o usado na criação do nGram\")\n",
        "        for i in range(len(nGram) - 1 ) :\n",
        "            var = (jaro.original_metric(nGram[i] , nGram[i + 1] ) , nGram[i+1] ,i + 1 )\n",
        "            for j in range( i + 1,len(nGram)) :\n",
        "                if jaro.original_metric(nGram[i] , nGram[j] ) >  var[0] :\n",
        "                    var = (jaro.original_metric(nGram[i] , nGram[j] ) , nGram[j] , j )\n",
        "            aux = nGram[i + 1]\n",
        "            nGram[i + 1] = var[1]\n",
        "            try :\n",
        "                nGram[var[2]]= aux\n",
        "            except :\n",
        "                print(j)\n",
        "            \n",
        "        return tuple(nGram)\n",
        "    def text2idx(self , text : str , nGram2idx : dict , n )-> tuple :\n",
        "        '''Se nGram2idx não possui posição do dicionario dedicada ao espaço em \n",
        "        branco(\" \") este será representado com indíce len(nGram2idx)'''\n",
        "        text = text.split()\n",
        "        aux = []\n",
        "        for word in text :\n",
        "            begin = 0\n",
        "            size  = n\n",
        "            tkn = True\n",
        "            while tkn :\n",
        "                try :\n",
        "                    aux += [nGram2idx[word[begin:size]]]\n",
        "                    begin = size\n",
        "                    size  = n\n",
        "                    if begin == len(word):\n",
        "                        tkn   = False\n",
        "                except :\n",
        "                    size -= 1\n",
        "            try :\n",
        "              aux += [nGram2idx[\" \"]]\n",
        "            except :\n",
        "              aux += [len(nGram2idx)]\n",
        "        return tuple(aux[:-1])\n",
        "un = nGram_Utils()\n",
        "print(len({1:2,2:3}))\n",
        "print(un.charNgram(\"cincocinsa\" , 4 ))\n",
        "print(un.jaroWinkler_Sort(un.charNgram(\"cincocinsa\" , 4 ) , 4 ))\n",
        "print(jaro.jaro_metric(\"abco\",\"bc\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "LOLkChh_deHk",
        "outputId": "f14e931f-fb6e-4e70-f4c5-c5a208acc01d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-98df0953c658>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    $jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib.parallel import Parallel\n",
        "%cd \"/content/{Neural_Dir}\"\n",
        "from BiLSTM import BiLSTM ,BiLSTM_Attention\n",
        "%cd /content/Chat_Bot\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col , row_number\n",
        "from pyspark.sql.window import Window\n",
        "import os\n",
        "import csv\n",
        "import pickle\n",
        "import joblib\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "df = spark.read.csv(\"/content/Chat_Bot/Kaggle_Twitter_Custumer_Support__archive/twcs/twcs.csv\" , header = True )\n",
        "# with open('/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/result3.csv/part-00000-94f3bc51-847d-44a3-a9d9-87a09b5284e8-c000.csv', 'r') as file:\n",
        "#     cs = csv.reader(file)\n",
        "#     cs = { i[0]:i for i in cs}\n",
        "#     # cs = [ i for i in cs]\n",
        "# pickle.dump(cs , open(\"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/datasetDict.pickle\",\"wb\"))\n",
        "path = \"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/datasetDict.pickle\"\n",
        "# cs = pickle.load(open(path,\"rb\"))\n",
        "# df.show()\n",
        "\n",
        "def loadPickle(path):\n",
        "    with open(path , \"rb\") as pt :\n",
        "        return joblib.load(pt)\n",
        "# cs = Parallel(n_jobs = 2 , backend = \"multiprocessing\")(delayed(loadPickle)(path))\n",
        "cs = loadPickle(path)\n",
        "\n",
        "dictest = {}\n",
        "\n",
        "def fun1(a):\n",
        "    fun2(a)\n",
        "    a[1] = \"oi\"\n",
        "    \n",
        "def fun2(a):\n",
        "    a[2] = \"Olá\"\n",
        "\n",
        "fun1(dictest)\n",
        "print(dictest)\n",
        "print(cs[\"tweet_id\"])\n",
        "print(cs[\"1\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "mp7seqT8u9Ot",
        "outputId": "c9c8ccc0-884d-4744-d16c-fdc62ab839a4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Machine-Learning__Deep-Learning\n",
            "/content/Chat_Bot\n",
            "{2: 'Olá', 1: 'oi'}\n",
            "['tweet_id', 'author_id', 'inbound', 'created_at', 'text', 'response_tweet_id', 'in_response_to_tweet_id']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-8c5b128fa382>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tweet_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cs[\"9\"])\n",
        "# cvv = { i[0]:(i[1][1] , i[1][4] , i[1][5] , i[1][6] ) for i in list(cs.items())}\n",
        "cvv = {}\n",
        "for i in list(cs.items()) :\n",
        "    try :\n",
        "        cvv[i[0]] = (i[1][1] , i[1][4] , i[1][5] , i[1][6] )\n",
        "    except :\n",
        "        print(i)\n",
        "        \n",
        "print(cvv[\"tweet_id\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28svrDOHy6iY",
        "outputId": "8545b55f-8038-4962-fc13-6bded59de632"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['9', 'sprintcare', 'False', 'Tue Oct 31 21:46:14 +0000 2017', '@115712 I would love the chance to review the account and provide assistance.', '', '8']\n",
            "('172981', ['172981', '156475', 'True', 'Fri Nov 24 22:16:01 +0000 2017', '@AppleSupport hey! I get a message on #macOS when I connect my #iPhoneX to #MacBookPro (15\\\\\",2017) using USB-C to #Lightning cable - it says it draws too much power??!! Should I be concerned??\\\\\"\"', '172979'])\n",
            "('486515', ['486515', 'marksandspencer', 'False', 'Fri Dec 01 15:43:09 +0000 2017', '@230767 Hi Patricia, we offer 29\\\\\",31\\\\\"\\\\\" and 33\\\\\"\\\\\" lg lengths\"', 'along with 27\\\\\\\\\" in our petite range. We used to offer XL but these didn\\'t sell as well as we\\'d hoped. We\\'ll tell our buyers you\\'d like to see more longer\"'])\n",
            "('637668', ['637668', '271197', 'True', 'Wed Nov 22 20:59:28 +0000 2017', '@SpotifyCares I have a 13\\\\\",mid-2012 Macbook pro. if you need processor/RAM specs I can also provide that.\\\\\"\"', '637670'])\n",
            "('1054460', ['1054460', '369154', 'True', 'Sat Oct 14 20:51:16 +0000 2017', '@115900 Really? Why we can\\'t watch the game this afternoon? You keep having “ problems with the program \\\\\",can\\'t keep our eye on the ball that way.\\\\\"\"', '1054458'])\n",
            "('1115026', ['1115026', '383114', 'True', 'Tue Oct 24 07:02:55 +0000 2017', 'Ordino su #Amazon un Monitor 21\\\\\",una Docking Station e una tastiera. Il corriere mi porta la tastiera. Il resto lo devo ritirare alle PT 😡\\\\\"\"', '1115025'])\n",
            "('1615538', ['1615538', 'AmazonHelp', 'False', 'Sun Nov 05 14:27:01 +0000 2017', '@495480 can also call our general help number\\\\\",you can hover over the blue lettering,and our toll-free number will appear! 2/2 ^KN\\\\\"\"'])\n",
            "('1039029', ['1039029', '552875', 'True', 'Wed Oct 18 12:52:08 +0000 2017', '@365828 @GWRHelp I wonder if leg room will be improved, or will I have to endure even more discomfort for additional cost? I\\'m only 6\\' 3\\\\\",it\\'s 2017=average\\\\\"\"', '1845671'])\n",
            "('2045564', ['2045564', '604953', 'True', 'Wed Oct 18 22:22:07 +0000 2017', 'Hey @AmericanAir, if this is your idea of legroom now, I\\'m switching to @Delta or @116450 for good. I\\'m 6\\'3\\\\\",not 7\\'0\\\\\"\\\\\". https://t.co/0tuP3cbswe\\\\\"\"', '2045562'])\n",
            "('2054598', ['2054598', '593981', 'True', 'Thu Oct 05 05:33:20 +0000 2017', '@AppleSupport Can you please fix this bug? German locale, OS 10.12.6. At least there must be a warning that \\\\\",\\\\\"\\\\\" should be used. @81903 https://t.co/gHiz9Dn8e1\\\\\"\"', '2054597'])\n",
            "('2254296', ['2254296', '656662', 'True', 'Mon Nov 13 14:22:34 +0000 2017', '@AskTarget Thanks.  I\\'m 5\\'2\\\\\",and even the mid-rise short sizes are too high.  #lowrise  : )\\\\\"\"', ''])\n",
            "('2290015', ['2290015', '665254', 'True', 'Sat Nov 11 19:29:09 +0000 2017', '@MicrosoftHelps Power button 30\\\\\",Two button reboot,etc.\\\\\"\"'])\n",
            "('2449648', ['2449648', '702084', 'True', 'Sun Oct 29 15:49:32 +0000 2017', '@AzureSupport a36-f110-442b-a11e-c8111a54db07\\\\\",\\\\\"\\\\\"upn\\\\\"\\\\\":\\\\\"\\\\\"__email__\\\\\"\\\\\"\"', '\\\\\\\\\"tenantId\\\\\"\\\\\":\\\\\"\\\\\"22d63ca0-892a-4b2a-93d5-4bb0d8b4e5ad\\\\\"\\\\\"\"'])\n",
            "('2880592', ['2880592', 'UPSHelp', 'False', 'Tue Nov 28 08:39:52 +0000 2017', '@799370 Log onto https://t.co/5oMU69kAgc, click the white arrow next to your name, and scroll to preferences. On the next pg, click on Memberships in the My Choice column. Next page, click \\'Cancel My Membership\\\\\",^AD\\\\\"\"', ''])\n",
            "('author_id', 'text', 'response_tweet_id', 'in_response_to_tweet_id')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,15):\n",
        "    print(cvv[str(i)])\n",
        "# pickle.dump(cvv , open(\"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/datasetDict_Sucinto.pickle\",\"wb\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KquEw-Cq5XMq",
        "outputId": "ec99e293-a3e5-4515-c6b3-0daf8aaa75ca"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('sprintcare', '@115712 I understand. I would like to assist you. We would need to get you into a private secured link to further assist.', '2', '3')\n",
            "('115712', '@sprintcare and how do you propose we do that', '', '1')\n",
            "('115712', '@sprintcare I have sent several private messages and no one is responding as usual', '1', '4')\n",
            "('sprintcare', '@115712 Please send us a Private Message so that we can further assist you. Just click ‘Message’ at the top of your profile.', '3', '5')\n",
            "('115712', '@sprintcare I did.', '4', '6')\n",
            "('sprintcare', '@115712 Can you please send us a private message, so that I can gain further details about your account?', '5,7', '8')\n",
            "('115712', '@sprintcare the only way I can get a response is to tweet apparently', '', '6')\n",
            "('115712', '@sprintcare is the worst customer service', '9,6,10', '')\n",
            "('sprintcare', '@115712 I would love the chance to review the account and provide assistance.', '', '8')\n",
            "('sprintcare', '@115712 Hello! We never like our customers to feel like they are not valued.', '', '8')\n",
            "('sprintcare', '@115713 This is saddening to hear. Please shoot us a DM, so that we can look into this for you. -KC', '', '12')\n",
            "('115713', '@sprintcare You gonna magically change your connectivity for me and my whole family ? 🤥 💯', '11,13,14', '15')\n",
            "('sprintcare', \"@115713 I would really like to work with you to have this resolved. Kindly send us a DM. I'm here for you! -ResolutionSup SR\", '', '12')\n",
            "('sprintcare', \"@115713 Hi, my name is Shantel, I'm a resolution supervisor here with Sprint. Your issues was brought to my attention.  1/2 -ResolutionSup SR\", '', '12')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(df.where(df.tweet_id == 2).select(\"text\").show())\n",
        "# w2 = Window.orderBy(col(\"tweet_id\"))\n",
        "df2 = df.filter( (df.tweet_id >= 1) & (df.text != \"\") )\n",
        "\n",
        "# df2 = spark.createDataFrame(df2)\n",
        "# df2.write.csv(\"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/teste\", mode= 'overwrite')\n",
        "# df2.write.format('csv').option('header',\n",
        "#                                True).mode('overwrite').option('sep',\n",
        "#                                                               ',').save(\"/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/teste\")\n",
        "# os.system(\"cat /content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/teste/p* > /content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/teste.csv\")\n",
        "df2.coalesce(1).write.format('csv').option('header',True).mode(\"overwrite\").save('/content/drive/MyDrive/Github_Dir/Chat_Bot/Chat_Bot/result3.csv')\n",
        "df2.show(40)\n",
        "\n",
        "# df2 = [list(row)  for row in df2.collect()]\n",
        "# df2 = df2.toPandas()\n",
        "# print(df2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9LuFnCLVTpq",
        "outputId": "cf2afab9-30c6-4088-b02b-b57a63ca8418"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------+-------+--------------------+--------------------+-----------------+-----------------------+\n",
            "|tweet_id|     author_id|inbound|          created_at|                text|response_tweet_id|in_response_to_tweet_id|\n",
            "+--------+--------------+-------+--------------------+--------------------+-----------------+-----------------------+\n",
            "|       1|    sprintcare|  False|Tue Oct 31 22:10:...|@115712 I underst...|                2|                      3|\n",
            "|       2|        115712|   True|Tue Oct 31 22:11:...|@sprintcare and h...|             null|                      1|\n",
            "|       3|        115712|   True|Tue Oct 31 22:08:...|@sprintcare I hav...|                1|                      4|\n",
            "|       4|    sprintcare|  False|Tue Oct 31 21:54:...|@115712 Please se...|                3|                      5|\n",
            "|       5|        115712|   True|Tue Oct 31 21:49:...|  @sprintcare I did.|                4|                      6|\n",
            "|       6|    sprintcare|  False|Tue Oct 31 21:46:...|@115712 Can you p...|              5,7|                      8|\n",
            "|       8|        115712|   True|Tue Oct 31 21:45:...|@sprintcare is th...|           9,6,10|                   null|\n",
            "|      11|    sprintcare|  False|Tue Oct 31 22:10:...|@115713 This is s...|             null|                     12|\n",
            "|      12|        115713|   True|Tue Oct 31 22:04:...|@sprintcare You g...|         11,13,14|                     15|\n",
            "|      15|    sprintcare|  False|Tue Oct 31 20:03:...|@115713 We unders...|               12|                     16|\n",
            "|      16|        115713|   True|Tue Oct 31 20:00:...|@sprintcare Since...|               15|                     17|\n",
            "|      17|    sprintcare|  False|Tue Oct 31 19:59:...|@115713 H there! ...|               16|                     18|\n",
            "|      18|        115713|   True|Tue Oct 31 19:56:...|@115714 y’all lie...|               17|                   null|\n",
            "|      19|    sprintcare|  False|Tue Oct 31 22:10:...|@115715 Please se...|             null|                     20|\n",
            "|      20|        115715|   True|Tue Oct 31 22:03:...|@115714 whenever ...|               19|                   null|\n",
            "|      21|  Ask_Spectrum|  False|Tue Oct 31 22:14:...|@115716 What info...|            22,23|                     24|\n",
            "|      22|        115716|   True|Tue Oct 31 22:16:...|@Ask_Spectrum Wou...|               25|                     21|\n",
            "|      25|  Ask_Spectrum|  False|Tue Oct 31 22:18:...|@115716 Our depar...|               26|                     22|\n",
            "|      26|        115716|   True|Tue Oct 31 22:19:...|@Ask_Spectrum I r...|               27|                     25|\n",
            "|      27|  Ask_Spectrum|  False|Tue Oct 31 22:21:...|@115716 No thank ...|             null|                     26|\n",
            "|      23|        115716|   True|Tue Oct 31 22:16:...|@Ask_Spectrum The...|             null|                     21|\n",
            "|      24|        115716|   True|Tue Oct 31 22:13:...|@Ask_Spectrum Tha...|               21|                     28|\n",
            "|      28|  Ask_Spectrum|  False|Tue Oct 31 22:05:...|@115716 The infor...|               24|                     29|\n",
            "|      29|        115716|   True|Tue Oct 31 22:01:...|actually that's a...|               28|                   null|\n",
            "|      30|  Ask_Spectrum|  False|Tue Oct 31 22:12:...|@115717 Hello, My...|             null|                     31|\n",
            "|      31|        115717|   True|Tue Oct 31 22:06:...|Yo @Ask_Spectrum,...|               30|                   null|\n",
            "|      32|  Ask_Spectrum|  False|Tue Oct 31 22:10:...|@115718 I apologi...|             null|                     33|\n",
            "|      33|        115718|   True|Tue Oct 31 22:06:...|My picture on @As...|               32|                   null|\n",
            "|      34|VerizonSupport|  False|Tue Oct 31 22:13:...|@115719 Help has ...|             null|                   null|\n",
            "|      35|        115719|   True|Tue Oct 31 22:49:...|@VerizonSupport I...|               37|                     34|\n",
            "|      37|VerizonSupport|  False|Tue Oct 31 22:52:...|@115719 Awesome! ...|             null|                   null|\n",
            "|      36|        115719|   True|Tue Oct 31 22:10:...|somebody from @Ve...|               34|                   null|\n",
            "|      38|VerizonSupport|  False|Tue Oct 31 22:13:...|@115720 Have your...|             null|                   null|\n",
            "|      39|        115720|   True|Tue Oct 31 22:12:...|@VerizonSupport M...|               38|                   null|\n",
            "|      40|VerizonSupport|  False|Tue Oct 31 22:12:...|@115721 Please fo...|             null|                   null|\n",
            "|      41|        115721|   True|Tue Oct 31 22:24:...|@VerizonSupport W...|               43|                     40|\n",
            "|      43|VerizonSupport|  False|Tue Oct 31 22:29:...|@115721 We would ...|             null|                   null|\n",
            "|      44|        115721|   True|Tue Oct 31 22:32:...|@VerizonSupport H...|               45|                     43|\n",
            "|      45|VerizonSupport|  False|Tue Oct 31 22:36:...|@115721 We can us...|             null|                   null|\n",
            "|      42|        115721|   True|Tue Oct 31 22:06:...|@115722 MD. And t...|               40|                     46|\n",
            "+--------+--------------+-------+--------------------+--------------------+-----------------+-----------------------+\n",
            "only showing top 40 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path = \"/content/drive/MyDrive/Colab Notebooks/Chat_Bot.ipynb\"\n",
        "# !rsync -aP \"{path}\" /content/Chat_Bot\n",
        "\n",
        "# !git clone \"{Git_CB_Path}\" ./temp\n",
        "# !rsync -aP /content/Chat_Bot/* ./temp\n",
        "# %cd ./temp\n",
        "# !git add -u\n",
        "# !git commit -m \"update\"\n",
        "# !git config user.email \"limaalyson@hotmail.com\"\n",
        "# !git config user.name \"Alyson_Google_Colab\"\n",
        "# !git push origin master\n",
        "# %cd /content\n",
        "# !rm -rf ./temp\n"
      ],
      "metadata": {
        "id": "idUUlda31aaZ"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}